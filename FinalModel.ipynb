{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "%run config.ipynb\n",
    "# %run keras-bert.py\n",
    "import os\n",
    "import random\n",
    "import math\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "from official.modeling import tf_utils\n",
    "from official import nlp\n",
    "from official.nlp import optimization\n",
    "from official.nlp import bert\n",
    "from official.nlp.bert.tokenization import FullTokenizer\n",
    "from official.nlp.bert.configs import BertConfig\n",
    "from official.nlp.bert.bert_models import classifier_model\n",
    "\n",
    "from keras_bert.bert import get_model\n",
    "from keras_bert.loader import load_trained_model_from_checkpoint\n",
    "\n",
    "from transformers import BertForSequenceClassification\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", tf.config.experimental.list_physical_devices('GPU'))\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Input, Dense, Embedding, LSTM, Bidirectional, GlobalMaxPooling1D, GlobalAveragePooling1D, Dropout, Conv1D, GlobalMaxPool1D, GlobalAvgPool1D\n",
    "from tensorflow.keras.models import Model, clone_model, Sequential, load_model\n",
    "from tensorflow.keras.metrics import RootMeanSquaredError\n",
    "\n",
    "import json\n",
    "import pickle\n",
    "# from keras import backend as K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:using Adamw optimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_word_ids  shape: (268540, 307)\n",
      "input_mask      shape: (268540, 307)\n",
      "input_type_ids  shape: (268540, 307)\n",
      "X_train_labels shape: (268540,)\n",
      "input_word_ids  shape: (132267, 273)\n",
      "input_mask      shape: (132267, 273)\n",
      "input_type_ids  shape: (132267, 273)\n",
      "X_train_labels shape: (132267,)\n",
      "Wall time: 4.54 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['bert_config.json',\n",
       " 'bert_model.ckpt.data-00000-of-00001',\n",
       " 'bert_model.ckpt.index',\n",
       " 'vocab.txt']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "import pickle\n",
    "with open('data/train_test_bert.pkl', 'rb') as f:\n",
    "    X_train, X_test, y_train, y_test = pickle.load(f)\n",
    "\n",
    "for key, value in X_train.items():\n",
    "  print(f'{key:15s} shape: {value.shape}')\n",
    "\n",
    "print(f'X_train_labels shape: {y_train.shape}')\n",
    "\n",
    "for key, value in X_test.items():\n",
    "  print(f'{key:15s} shape: {value.shape}')\n",
    "\n",
    "print(f'X_train_labels shape: {y_test.shape}')\n",
    "\n",
    "# Set up epochs and steps\n",
    "epochs = 3\n",
    "batch_size = 128\n",
    "eval_batch_size = 32\n",
    "\n",
    "train_data_size = len(y_train)\n",
    "steps_per_epoch = int(train_data_size / batch_size)\n",
    "num_train_steps = steps_per_epoch * epochs\n",
    "warmup_steps = int(epochs * train_data_size * 0.1 / batch_size)\n",
    "\n",
    "# creates an optimizer with learning rate schedule\n",
    "optimizer = nlp.optimization.create_optimizer(2e-4, num_train_steps=num_train_steps, num_warmup_steps=warmup_steps)\n",
    "\n",
    "bert_folder = \"data/bert_custom/\"\n",
    "tf.io.gfile.listdir(bert_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[\"review_text_after_cleaning\"]\n",
    "y = df[\"review_stars\"]\n",
    "y = y.apply(lambda x : x - 1) # convert range(1,6) to range(0,5) for more precise when adding dense layer\n",
    "# y = y.apply(lambda x : 1 if x else 0)\n",
    "df_train, df_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_word_ids': <tf.Tensor: shape=(268540, 307), dtype=int32, numpy=\n",
       " array([[  101,  6187,  2271, ...,     0,     0,     0],\n",
       "        [  101, 24970,  2833, ...,     0,     0,     0],\n",
       "        [  101,  2173, 12721, ...,     0,     0,     0],\n",
       "        ...,\n",
       "        [  101,  2613,  3669, ...,     0,     0,     0],\n",
       "        [  101,  2293,  2717, ...,     0,     0,     0],\n",
       "        [  101,  2253,  2265, ...,     0,     0,     0]])>,\n",
       " 'input_mask': <tf.Tensor: shape=(268540, 307), dtype=int32, numpy=\n",
       " array([[1, 1, 1, ..., 0, 0, 0],\n",
       "        [1, 1, 1, ..., 0, 0, 0],\n",
       "        [1, 1, 1, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [1, 1, 1, ..., 0, 0, 0],\n",
       "        [1, 1, 1, ..., 0, 0, 0],\n",
       "        [1, 1, 1, ..., 0, 0, 0]])>,\n",
       " 'input_type_ids': <tf.Tensor: shape=(268540, 307), dtype=int32, numpy=\n",
       " array([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]])>}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "class BertLayer(tf.layers.Layer):\n",
    "    def __init__(self, n_fine_tune_layers=4, **kwargs):\n",
    "        self.n_fine_tune_layers = n_fine_tune_layers\n",
    "        self.trainable = True\n",
    "        self.output_size = 256\n",
    "        super(BertLayer, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        config_file = os.path.join(bert_folder, 'bert_config.json')\n",
    "        checkpoint_file = os.path.join(bert_folder, 'bert_model.ckpt')\n",
    "        self.bert = load_trained_model_from_checkpoint(config_file, checkpoint_file, training=True, seq_len=256)\n",
    "#         self.bert = hub.Module(\n",
    "#             bert_folder,\n",
    "#             trainable=self.trainable,\n",
    "#             name=\"{}_module\".format(self.name)\n",
    "#         )\n",
    "        trainable_vars = self.bert.variables\n",
    "        \n",
    "        # Remove unused layers\n",
    "        trainable_vars = [var for var in trainable_vars if not \"/cls/\" in var.name]\n",
    "        \n",
    "        # Select how many layers to fine tune\n",
    "        trainable_vars = trainable_vars[-self.n_fine_tune_layers :]\n",
    "        \n",
    "        # Add to trainable weights\n",
    "        for var in trainable_vars:\n",
    "            self._trainable_weights.append(var)\n",
    "        \n",
    "        # Add non-trainable weights\n",
    "        for var in self.bert.variables:\n",
    "            if var not in self._trainable_weights:\n",
    "                self._non_trainable_weights.append(var)\n",
    "        \n",
    "        super(BertLayer, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        inputs = [K.cast(x, dtype=\"int32\") for x in inputs]\n",
    "        input_ids, input_mask, segment_ids = inputs\n",
    "        bert_inputs = dict(\n",
    "            input_ids=input_ids, input_mask=input_mask, segment_ids=segment_ids\n",
    "        )\n",
    "        result = self.bert(inputs=bert_inputs, signature=\"tokens\", as_dict=True)[\n",
    "            \"pooled_output\"\n",
    "        ]\n",
    "        return result\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], self.output_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "OperatorNotAllowedInGraphError",
     "evalue": "using a `tf.Tensor` as a Python `bool` is not allowed in Graph execution. Use Eager execution or decorate this function with @tf.function.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOperatorNotAllowedInGraphError\u001b[0m            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-46-f8fa8f7a2544>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m# Instantiate the custom Bert Layer defined above\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mbert_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBertLayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbert_inputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;31m# Build the rest of the classifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mt:\\python\\python38\\lib\\site-packages\\tensorflow\\python\\keras\\legacy_tf_layers\\base.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    545\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    546\u001b[0m       \u001b[1;31m# Actually call layer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 547\u001b[1;33m       \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mLayer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    548\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mt:\\python\\python38\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    923\u001b[0m     \u001b[1;31m# >> model = tf.keras.Model(inputs, outputs)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    924\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0m_in_functional_construction_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 925\u001b[1;33m       return self._functional_construction_call(inputs, args, kwargs,\n\u001b[0m\u001b[0;32m    926\u001b[0m                                                 input_list)\n\u001b[0;32m    927\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mt:\\python\\python38\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m_functional_construction_call\u001b[1;34m(self, inputs, args, kwargs, input_list)\u001b[0m\n\u001b[0;32m   1096\u001b[0m         \u001b[1;31m# Build layer if applicable (if the `build` method has been\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1097\u001b[0m         \u001b[1;31m# overridden).\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1098\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_build\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1099\u001b[0m         \u001b[0mcast_inputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cast_inputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1100\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mt:\\python\\python38\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m_maybe_build\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2641\u001b[0m         \u001b[1;31m# operations.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2642\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmaybe_init_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2643\u001b[1;33m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint:disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2644\u001b[0m       \u001b[1;31m# We must set also ensure that the layer is marked as built, and the build\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2645\u001b[0m       \u001b[1;31m# shape is stored since user defined build functions may not be calling\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-45-0939b22fa795>\u001b[0m in \u001b[0;36mbuild\u001b[1;34m(self, input_shape)\u001b[0m\n\u001b[0;32m     31\u001b[0m         \u001b[1;31m# Add non-trainable weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mvar\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbert\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvariables\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0mvar\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_trainable_weights\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_non_trainable_weights\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mt:\\python\\python38\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m__bool__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    875\u001b[0m       \u001b[0;31m`\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    876\u001b[0m     \"\"\"\n\u001b[1;32m--> 877\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_disallow_bool_casting\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    878\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    879\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m__nonzero__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mt:\\python\\python38\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_disallow_bool_casting\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    488\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    489\u001b[0m       \u001b[1;31m# Default: V1-style Graph execution.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 490\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_disallow_in_graph_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"using a `tf.Tensor` as a Python `bool`\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    491\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    492\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_disallow_iteration\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mt:\\python\\python38\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_disallow_in_graph_mode\u001b[1;34m(self, task)\u001b[0m\n\u001b[0;32m    475\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    476\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_disallow_in_graph_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 477\u001b[1;33m     raise errors.OperatorNotAllowedInGraphError(\n\u001b[0m\u001b[0;32m    478\u001b[0m         \u001b[1;34m\"{} is not allowed in Graph execution. Use Eager execution or decorate\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    479\u001b[0m         \" this function with @tf.function.\".format(task))\n",
      "\u001b[1;31mOperatorNotAllowedInGraphError\u001b[0m: using a `tf.Tensor` as a Python `bool` is not allowed in Graph execution. Use Eager execution or decorate this function with @tf.function."
     ]
    }
   ],
   "source": [
    "# Build model\n",
    "max_seq_length = 256\n",
    "in_id = tf.keras.layers.Input(shape=(max_seq_length,), name=\"input_ids\")\n",
    "in_mask = tf.keras.layers.Input(shape=(max_seq_length,), name=\"input_masks\")\n",
    "in_segment = tf.keras.layers.Input(shape=(max_seq_length,), name=\"segment_ids\")\n",
    "bert_inputs = [in_id, in_mask, in_segment]\n",
    "\n",
    "# Instantiate the custom Bert Layer defined above\n",
    "bert_output = BertLayer()(bert_inputs)\n",
    "\n",
    "# Build the rest of the classifier \n",
    "dense = tf.keras.layers.Dense(256, activation='relu')(bert_output)\n",
    "pred = tf.keras.layers.Dense(1, activation='sigmoid')(dense)\n",
    "\n",
    "model = tf.keras.models.Model(inputs=bert_inputs, outputs=pred)\n",
    "# model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# model.fit(\n",
    "#     [train_input_ids, train_input_masks, train_segment_ids], \n",
    "#     train_labels,\n",
    "#     validation_data=([test_input_ids, test_input_masks, test_segment_ids], test_labels),\n",
    "#     epochs=1,\n",
    "#     batch_size=32\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hidden_size': 312,\n",
       " 'hidden_act': 'relu',\n",
       " 'initializer_range': 0.02,\n",
       " 'vocab_size': 30522,\n",
       " 'hidden_dropout_prob': 0.2,\n",
       " 'num_attention_heads': 4,\n",
       " 'type_vocab_size': 2,\n",
       " 'max_position_embeddings': 308,\n",
       " 'num_hidden_layers': 4,\n",
       " 'intermediate_size': 768,\n",
       " 'attention_probs_dropout_prob': 0.2}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_config_file = os.path.join(bert_folder, \"bert_config.json\")\n",
    "config_dict = json.loads(tf.io.gfile.GFile(bert_config_file).read())\n",
    "bert_config = bert.configs.BertConfig.from_dict(config_dict)\n",
    "config_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:using Adamw optimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "2098/2098 [==============================] - 1015s 484ms/step - loss: 1.2622 - rmse: 1.1235 - mae: 0.8033 - val_loss: 0.5803 - val_rmse: 0.7618 - val_mae: 0.5341\n",
      "Epoch 2/3\n",
      "2098/2098 [==============================] - 897s 427ms/step - loss: 0.5618 - rmse: 0.7496 - mae: 0.5270 - val_loss: 0.5667 - val_rmse: 0.7528 - val_mae: 0.4917\n",
      "Epoch 3/3\n",
      "2098/2098 [==============================] - 777s 370ms/step - loss: 0.5035 - rmse: 0.7096 - mae: 0.4932 - val_loss: 0.5650 - val_rmse: 0.7516 - val_mae: 0.4877\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x169f9b16b20>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creates an optimizer with learning rate schedule\n",
    "optimizer = nlp.optimization.create_optimizer(2e-4, num_train_steps=num_train_steps, num_warmup_steps=warmup_steps)\n",
    "\n",
    "bert_classifier1, bert_encoder1 = bert.bert_models.classifier_model(bert_config, num_labels=5)\n",
    "bert_classifier1.compile(optimizer=optimizer, loss='mse', metrics=[tf.keras.metrics.RootMeanSquaredError('rmse'), 'mae'])\n",
    "bert_classifier1.fit(X_train, y_train, validation_data=(X_test, y_test), batch_size=batch_size, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data for LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>business_id</th>\n",
       "      <th>review_stars</th>\n",
       "      <th>user_review_count</th>\n",
       "      <th>user_elite</th>\n",
       "      <th>user_friends</th>\n",
       "      <th>user_fans</th>\n",
       "      <th>user_average_stars</th>\n",
       "      <th>user_total_compliments</th>\n",
       "      <th>business_name</th>\n",
       "      <th>business_stars</th>\n",
       "      <th>review_text_after_cleaning</th>\n",
       "      <th>num_user_friends</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lXSEWDtaiaQcxj5Nuxx6JA</td>\n",
       "      <td>fWqtOUpCFv6rmaacYZdkEQ</td>\n",
       "      <td>0z010Dfuv-PLUIukFhYEHQ</td>\n",
       "      <td>5</td>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>2.95</td>\n",
       "      <td>2</td>\n",
       "      <td>Hydrate Salon and Spa</td>\n",
       "      <td>4.0</td>\n",
       "      <td>great spot fair price good servic profession s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Au1-zoHWO3VIlI48blfixA</td>\n",
       "      <td>DlGBaNwQsAeKAW75iHVEzg</td>\n",
       "      <td>0z010Dfuv-PLUIukFhYEHQ</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>MCX2QsAl79d4-Z-H9YJPEw, DN0YgFN7S7teowvOC0mwNA...</td>\n",
       "      <td>2</td>\n",
       "      <td>3.60</td>\n",
       "      <td>1</td>\n",
       "      <td>Hydrate Salon and Spa</td>\n",
       "      <td>4.0</td>\n",
       "      <td>hair facial alway feel incred welcom everyon g...</td>\n",
       "      <td>531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dw6k8HwpXBZ2xD_MC-9dDg</td>\n",
       "      <td>YBqPdDh0KOdAfMv_9U4jOw</td>\n",
       "      <td>0z010Dfuv-PLUIukFhYEHQ</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>FC8HuS-i-8XDv0HFGVgnbQ, 66MQLCs9yP2PgKZLTck66Q...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.75</td>\n",
       "      <td>0</td>\n",
       "      <td>Hydrate Salon and Spa</td>\n",
       "      <td>4.0</td>\n",
       "      <td>schedul minut late also schedul color girl fro...</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>T8hb6_yy0iJoM-TsNtwx2Q</td>\n",
       "      <td>5kDWszBfoqNjwohHZ3vpAw</td>\n",
       "      <td>0z010Dfuv-PLUIukFhYEHQ</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>LLapZiT6_844J5rfLQgQrg, a4_sKXaN2Cfvhb9v52WSyg...</td>\n",
       "      <td>0</td>\n",
       "      <td>4.78</td>\n",
       "      <td>0</td>\n",
       "      <td>Hydrate Salon and Spa</td>\n",
       "      <td>4.0</td>\n",
       "      <td>thier custom open door thrill attent gave hair...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>QSOdfF9TSGyOMU1cUJUe5g</td>\n",
       "      <td>lNyihs-KKOviAvBBXa1xlw</td>\n",
       "      <td>0z010Dfuv-PLUIukFhYEHQ</td>\n",
       "      <td>5</td>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "      <td>hnvx0UISDCcrJpc5ysLmnA, Fhzf1hxz2o6GzyrTncB59Q...</td>\n",
       "      <td>1</td>\n",
       "      <td>3.76</td>\n",
       "      <td>2</td>\n",
       "      <td>Hydrate Salon and Spa</td>\n",
       "      <td>4.0</td>\n",
       "      <td>want great cut color word you quach start see ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                review_id                 user_id             business_id  \\\n",
       "0  lXSEWDtaiaQcxj5Nuxx6JA  fWqtOUpCFv6rmaacYZdkEQ  0z010Dfuv-PLUIukFhYEHQ   \n",
       "1  Au1-zoHWO3VIlI48blfixA  DlGBaNwQsAeKAW75iHVEzg  0z010Dfuv-PLUIukFhYEHQ   \n",
       "2  dw6k8HwpXBZ2xD_MC-9dDg  YBqPdDh0KOdAfMv_9U4jOw  0z010Dfuv-PLUIukFhYEHQ   \n",
       "3  T8hb6_yy0iJoM-TsNtwx2Q  5kDWszBfoqNjwohHZ3vpAw  0z010Dfuv-PLUIukFhYEHQ   \n",
       "4  QSOdfF9TSGyOMU1cUJUe5g  lNyihs-KKOviAvBBXa1xlw  0z010Dfuv-PLUIukFhYEHQ   \n",
       "\n",
       "   review_stars  user_review_count  user_elite  \\\n",
       "0             5                 55           0   \n",
       "1             5                 15           0   \n",
       "2             2                  8           0   \n",
       "3             5                  9           0   \n",
       "4             5                 52           0   \n",
       "\n",
       "                                        user_friends  user_fans  \\\n",
       "0                                               None          0   \n",
       "1  MCX2QsAl79d4-Z-H9YJPEw, DN0YgFN7S7teowvOC0mwNA...          2   \n",
       "2  FC8HuS-i-8XDv0HFGVgnbQ, 66MQLCs9yP2PgKZLTck66Q...          0   \n",
       "3  LLapZiT6_844J5rfLQgQrg, a4_sKXaN2Cfvhb9v52WSyg...          0   \n",
       "4  hnvx0UISDCcrJpc5ysLmnA, Fhzf1hxz2o6GzyrTncB59Q...          1   \n",
       "\n",
       "   user_average_stars  user_total_compliments          business_name  \\\n",
       "0                2.95                       2  Hydrate Salon and Spa   \n",
       "1                3.60                       1  Hydrate Salon and Spa   \n",
       "2                1.75                       0  Hydrate Salon and Spa   \n",
       "3                4.78                       0  Hydrate Salon and Spa   \n",
       "4                3.76                       2  Hydrate Salon and Spa   \n",
       "\n",
       "   business_stars                         review_text_after_cleaning  \\\n",
       "0             4.0  great spot fair price good servic profession s...   \n",
       "1             4.0  hair facial alway feel incred welcom everyon g...   \n",
       "2             4.0  schedul minut late also schedul color girl fro...   \n",
       "3             4.0  thier custom open door thrill attent gave hair...   \n",
       "4             4.0  want great cut color word you quach start see ...   \n",
       "\n",
       "   num_user_friends  \n",
       "0                 0  \n",
       "1               531  \n",
       "2                22  \n",
       "3                 4  \n",
       "4                 5  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/yelp_academic_dataset_final.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[\"review_text_after_cleaning\"]\n",
    "y = df[\"review_stars\"].apply(lambda x : x-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_VOCAB_SIZE = 50000\n",
    "tokenizer = Tokenizer(num_words=MAX_VOCAB_SIZE)\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "sequences_train = tokenizer.texts_to_sequences(X_train)\n",
    "sequences_test = tokenizer.texts_to_sequences(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 222351 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "word2idx = tokenizer.word_index\n",
    "V = len(word2idx)\n",
    "print('Found %s unique tokens.' % V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data train tensor: (671373, 150)\n",
      "Shape of data test tensor: (330677, 150)\n"
     ]
    }
   ],
   "source": [
    "X_train_text = pad_sequences(sequences_train, maxlen=150)\n",
    "print('Shape of data train tensor:', X_train_text.shape)\n",
    "\n",
    "T = X_train_text.shape[1]\n",
    "\n",
    "X_test_text = pad_sequences(sequences_test, maxlen=T)\n",
    "print('Shape of data test tensor:', X_test_text.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 150, 150)          7500000   \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection (None, 150, 150)          135600    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_2 ( (None, 150)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 151       \n",
      "=================================================================\n",
      "Total params: 7,635,751\n",
      "Trainable params: 7,635,751\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "lstm = load_model(\"models/lstm.h5\")\n",
    "lstm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = lstm.predict(X_test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.21576   ],\n",
       "       [ 3.3574724 ],\n",
       "       [ 3.8535378 ],\n",
       "       ...,\n",
       "       [-0.15520087],\n",
       "       [ 3.7164297 ],\n",
       "       [ 3.9894316 ]], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
