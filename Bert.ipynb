{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "%run config.ipynb\n",
    "import os\n",
    "import random\n",
    "import math\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "from official.modeling import tf_utils\n",
    "from official import nlp\n",
    "from official.nlp import bert\n",
    "\n",
    "# Load the required submodules\n",
    "import official.nlp.optimization\n",
    "import official.nlp.bert.bert_models\n",
    "import official.nlp.bert.configs\n",
    "import official.nlp.bert.run_classifier\n",
    "import official.nlp.bert.tokenization\n",
    "import official.nlp.data.classifier_data_lib\n",
    "import official.nlp.modeling.losses\n",
    "import official.nlp.modeling.models\n",
    "import official.nlp.modeling.networks\n",
    "\n",
    "from keras_bert.bert import get_model\n",
    "from keras_bert.loader import load_trained_model_from_checkpoint\n",
    "\n",
    "from transformers import BertForSequenceClassification\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", tf.config.experimental.list_physical_devices('GPU'))\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Input, Dense, Embedding, LSTM, Bidirectional, GlobalMaxPooling1D, GlobalAveragePooling1D, Dropout, Conv1D, GlobalMaxPool1D\n",
    "from tensorflow.keras.models import Model, clone_model, Sequential\n",
    "from tensorflow.keras.metrics import RootMeanSquaredError\n",
    "\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>business_id</th>\n",
       "      <th>review_stars</th>\n",
       "      <th>review_text</th>\n",
       "      <th>review_text_after_cleaning</th>\n",
       "      <th>user_review_count</th>\n",
       "      <th>user_elite</th>\n",
       "      <th>user_friends</th>\n",
       "      <th>user_fans</th>\n",
       "      <th>user_average_stars</th>\n",
       "      <th>user_total_compliments</th>\n",
       "      <th>business_name</th>\n",
       "      <th>business_categories</th>\n",
       "      <th>business_stars</th>\n",
       "      <th>to_recommend</th>\n",
       "      <th>num_user_friends</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>yNB39szX3M8mTEzTtsgoCw</td>\n",
       "      <td>Y1iCYGvLf4ifPoXlKLGq-w</td>\n",
       "      <td>o2Qh4SiGYJ7BK4hP7dfkrw</td>\n",
       "      <td>5</td>\n",
       "      <td>This is an amazing indian Bistro!!I If I do sa...</td>\n",
       "      <td>amaz bistroi say myself never cuisin glad expe...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Saffron Indian Bistro</td>\n",
       "      <td>Restaurants, Indian</td>\n",
       "      <td>4.5</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                review_id                 user_id             business_id  \\\n",
       "0  yNB39szX3M8mTEzTtsgoCw  Y1iCYGvLf4ifPoXlKLGq-w  o2Qh4SiGYJ7BK4hP7dfkrw   \n",
       "\n",
       "   review_stars                                        review_text  \\\n",
       "0             5  This is an amazing indian Bistro!!I If I do sa...   \n",
       "\n",
       "                          review_text_after_cleaning  user_review_count  \\\n",
       "0  amaz bistroi say myself never cuisin glad expe...                  1   \n",
       "\n",
       "   user_elite user_friends  user_fans  user_average_stars  \\\n",
       "0           0         None          0                 5.0   \n",
       "\n",
       "   user_total_compliments          business_name  business_categories  \\\n",
       "0                       0  Saffron Indian Bistro  Restaurants, Indian   \n",
       "\n",
       "   business_stars  to_recommend  num_user_friends  \n",
       "0             4.5          True                 0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/yelp_academic_dataset_sample005_filter.csv\")\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[\"review_text_after_cleaning\"]\n",
    "y = df[\"review_stars\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bert_config.json',\n",
       " 'bert_model.ckpt.data-00000-of-00001',\n",
       " 'bert_model.ckpt.index',\n",
       " 'vocab.txt']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_folder = \"data/uncased_L-2_H-128_A-2\"\n",
    "tf.io.gfile.listdir(bert_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size: 30522\n"
     ]
    }
   ],
   "source": [
    "# Set up tokenizer to generate Tensorflow dataset\n",
    "tokenizer = bert.tokenization.FullTokenizer(\n",
    "    vocab_file=os.path.join(bert_folder, \"vocab.txt\"),\n",
    "    do_lower_case=True)\n",
    "print(\"Vocab size:\", len(tokenizer.vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Input-Token (InputLayer)        [(None, 150)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Input-Segment (InputLayer)      [(None, 150)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Embedding-Token (TokenEmbedding [(None, 150, 128), ( 3906816     Input-Token[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "Embedding-Segment (Embedding)   (None, 150, 128)     256         Input-Segment[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Embedding-Token-Segment (Add)   (None, 150, 128)     0           Embedding-Token[0][0]            \n",
      "                                                                 Embedding-Segment[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Embedding-Position (PositionEmb (None, 150, 128)     19200       Embedding-Token-Segment[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "Embedding-Dropout (Dropout)     (None, 150, 128)     0           Embedding-Position[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "Embedding-Norm (LayerNormalizat (None, 150, 128)     256         Embedding-Dropout[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-MultiHeadSelfAttentio (None, None, 128)    66048       Embedding-Norm[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-MultiHeadSelfAttentio (None, None, 128)    0           Encoder-1-MultiHeadSelfAttention[\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-MultiHeadSelfAttentio (None, 150, 128)     0           Embedding-Norm[0][0]             \n",
      "                                                                 Encoder-1-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-MultiHeadSelfAttentio (None, 150, 128)     256         Encoder-1-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-FeedForward (FeedForw (None, 150, 128)     131712      Encoder-1-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-FeedForward-Dropout ( (None, 150, 128)     0           Encoder-1-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-FeedForward-Add (Add) (None, 150, 128)     0           Encoder-1-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-1-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-FeedForward-Norm (Lay (None, 150, 128)     256         Encoder-1-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-2-MultiHeadSelfAttentio (None, None, 128)    66048       Encoder-1-FeedForward-Norm[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-2-MultiHeadSelfAttentio (None, None, 128)    0           Encoder-2-MultiHeadSelfAttention[\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-2-MultiHeadSelfAttentio (None, 150, 128)     0           Encoder-1-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-2-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-2-MultiHeadSelfAttentio (None, 150, 128)     256         Encoder-2-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-2-FeedForward (FeedForw (None, 150, 128)     131712      Encoder-2-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-2-FeedForward-Dropout ( (None, 150, 128)     0           Encoder-2-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-2-FeedForward-Add (Add) (None, 150, 128)     0           Encoder-2-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-2-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-2-FeedForward-Norm (Lay (None, 150, 128)     256         Encoder-2-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "MLM-Dense (Dense)               (None, 150, 128)     16512       Encoder-2-FeedForward-Norm[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "MLM-Norm (LayerNormalization)   (None, 150, 128)     256         MLM-Dense[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "Extract (Extract)               (None, 128)          0           Encoder-2-FeedForward-Norm[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "MLM-Sim (EmbeddingSimilarity)   (None, 150, 30522)   30522       MLM-Norm[0][0]                   \n",
      "                                                                 Embedding-Token[0][1]            \n",
      "__________________________________________________________________________________________________\n",
      "Input-Masked (InputLayer)       [(None, 150)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "NSP-Dense (Dense)               (None, 128)          16512       Extract[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "MLM (Masked)                    (None, 150, 30522)   0           MLM-Sim[0][0]                    \n",
      "                                                                 Input-Masked[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "NSP (Dense)                     (None, 2)            258         NSP-Dense[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 4,387,132\n",
      "Trainable params: 4,387,132\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "config_file = os.path.join(bert_folder, 'bert_config.json')\n",
    "checkpoint_file = os.path.join(bert_folder, 'bert_model.ckpt')\n",
    "model = load_trained_model_from_checkpoint(config_file, checkpoint_file, training=True, seq_len=150)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_review(text):\n",
    "    return tokenizer.convert_tokens_to_ids(tokenizer.tokenize(text))\n",
    "tokenized_reviews = X_train.apply(tokenize_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[6187,\n",
       "  2271,\n",
       "  2868,\n",
       "  9530,\n",
       "  15900,\n",
       "  2072,\n",
       "  7661,\n",
       "  3805,\n",
       "  25540,\n",
       "  8490,\n",
       "  9530,\n",
       "  14028,\n",
       "  2296,\n",
       "  2239,\n",
       "  4297,\n",
       "  7630,\n",
       "  2094,\n",
       "  2033,\n",
       "  2187,\n",
       "  2868],\n",
       " 5,\n",
       " 20]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_with_len = [[review, y[i], len(review)] for i, review in enumerate(tokenized_reviews)]\n",
    "reviews_with_len[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(reviews_with_len)\n",
    "reviews_with_len.sort(key=lambda x: x[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[([8257], 3),\n",
       " ([3435], 5),\n",
       " ([2067], 1),\n",
       " ([6187], 2),\n",
       " ([1058], 5),\n",
       " ([24970], 5),\n",
       " ([7929], 3),\n",
       " ([2485], 5),\n",
       " ([14123], 2),\n",
       " ([2307], 4),\n",
       " ([5404], 5),\n",
       " ([2237], 4),\n",
       " ([2293], 3),\n",
       " ([2204], 5),\n",
       " ([8288], 5),\n",
       " ([2205], 1),\n",
       " ([24970], 2),\n",
       " ([2732], 4),\n",
       " ([2769], 4),\n",
       " ([3199], 2),\n",
       " ([3095], 5),\n",
       " ([1047], 5),\n",
       " ([3819], 5),\n",
       " ([3435], 2),\n",
       " ([2560], 5),\n",
       " ([2173], 1),\n",
       " ([2485], 5),\n",
       " ([4900], 4),\n",
       " ([24970], 5),\n",
       " ([2182], 1),\n",
       " ([2514], 5),\n",
       " ([2168], 5),\n",
       " ([4497], 5),\n",
       " ([2485, 2204], 4),\n",
       " ([22448, 15916], 5),\n",
       " ([3976, 2833], 2),\n",
       " ([2307, 2051], 4),\n",
       " ([2732, 3524], 4),\n",
       " ([14262, 7903], 5),\n",
       " ([2767, 3669], 3),\n",
       " ([2739, 4149], 3),\n",
       " ([2204, 2833], 4),\n",
       " ([7610, 2330], 2),\n",
       " ([3565, 2204], 3),\n",
       " ([5932, 10497], 1),\n",
       " ([26568, 2546], 5),\n",
       " ([2191, 11132], 1),\n",
       " ([13173, 6559], 3),\n",
       " ([12183, 4761], 3),\n",
       " ([2272, 2067], 4),\n",
       " ([10250, 10050], 3),\n",
       " ([23566, 2360], 5),\n",
       " ([2388, 20572], 5),\n",
       " ([8529, 2053], 5),\n",
       " ([4190, 4183], 4),\n",
       " ([2307, 28305], 4),\n",
       " ([15180, 25426], 5),\n",
       " ([4550, 4355], 4),\n",
       " ([2106, 10036], 2),\n",
       " ([9765, 24970], 5),\n",
       " ([2522, 9236], 4),\n",
       " ([7563, 17728], 4),\n",
       " ([24970, 18064], 5),\n",
       " ([17678, 2891], 4),\n",
       " ([2717, 21159], 4),\n",
       " ([3565, 8038], 4),\n",
       " ([15180, 25426], 5),\n",
       " ([2919, 2488], 2),\n",
       " ([2190, 3028], 3),\n",
       " ([14262, 2615], 5),\n",
       " ([17935, 3775], 2),\n",
       " ([2769, 2190], 5),\n",
       " ([1037, 4239], 5),\n",
       " ([2502, 4664], 5),\n",
       " ([2589, 2157], 4),\n",
       " ([2300, 2091], 1),\n",
       " ([2564, 4060], 5),\n",
       " ([9805, 2213], 4),\n",
       " ([10514, 6182], 5),\n",
       " ([2404, 2327], 4),\n",
       " ([17268, 4664], 5),\n",
       " ([3976, 2092], 2),\n",
       " ([4550, 4067], 4),\n",
       " ([2767, 3669], 3),\n",
       " ([15536, 8873], 4),\n",
       " ([7987, 9307], 5),\n",
       " ([2307, 2092], 5),\n",
       " ([2175, 2237], 5),\n",
       " ([2253, 2147, 2204], 1),\n",
       " ([14380, 19673, 7975], 5),\n",
       " ([2435, 2204, 21209], 1),\n",
       " ([2293, 3358, 2540], 5),\n",
       " ([3095, 8241, 2305], 5),\n",
       " ([12731, 17417, 14862], 4),\n",
       " ([26568, 16558, 6265], 2),\n",
       " ([2066, 19747, 10733], 5),\n",
       " ([2190, 2234, 4596], 4),\n",
       " ([2175, 2131, 7639], 4),\n",
       " ([2052, 2224, 2153], 4),\n",
       " ([8241, 15180, 25426], 4),\n",
       " ([5684, 4183, 2092], 3),\n",
       " ([2190, 5409, 2412], 4),\n",
       " ([2435, 9413, 10755], 5),\n",
       " ([6565, 7276, 2833], 4),\n",
       " ([2632, 4576, 2732], 3),\n",
       " ([8740, 10760, 3372], 2),\n",
       " ([10140, 2067, 8288], 5),\n",
       " ([2379, 2208, 2393], 2),\n",
       " ([4248, 2112, 2344], 4),\n",
       " ([3507, 2833, 2072], 5),\n",
       " ([2175, 2067, 2574], 5),\n",
       " ([2307, 14262, 7903], 5),\n",
       " ([5101, 4101, 2485], 5),\n",
       " ([2190, 18651, 7975], 5),\n",
       " ([5404, 30207, 1665], 3),\n",
       " ([3835, 4550, 2047], 1),\n",
       " ([3095, 2709, 7661], 5),\n",
       " ([2307, 2522, 16020], 4),\n",
       " ([2492, 2777, 2288], 5),\n",
       " ([6616, 11891, 7743], 4),\n",
       " ([2190, 3066, 2190], 2),\n",
       " ([13173, 6559, 6752], 5),\n",
       " ([5082, 2193, 7309], 5),\n",
       " ([20228, 2226, 5073], 3),\n",
       " ([2732, 2131, 21229], 1),\n",
       " ([6887, 16515, 2213], 2),\n",
       " ([3524, 2175, 2067], 4),\n",
       " ([4239, 15942, 2078], 5),\n",
       " ([13433, 21823, 2078], 5),\n",
       " ([4687, 2833, 3095], 5),\n",
       " ([9805, 7382, 2072], 1),\n",
       " ([10166, 17268, 4761], 4),\n",
       " ([4067, 21459, 2173], 5),\n",
       " ([3095, 15180, 25426], 5),\n",
       " ([2190, 2833, 8828], 2),\n",
       " ([2191, 2307, 11642], 1),\n",
       " ([2307, 8840, 11266], 5),\n",
       " ([2298, 2830, 2833], 5),\n",
       " ([2204, 2265, 20432], 5),\n",
       " ([3198, 2172, 2008], 4),\n",
       " ([2307, 7954, 2190], 4),\n",
       " ([8984, 3972, 28775], 4),\n",
       " ([6534, 10424, 2072], 3),\n",
       " ([5470, 10230, 2102], 4),\n",
       " ([10514, 9468, 5313], 5),\n",
       " ([2131, 6073, 27090], 4),\n",
       " ([2438, 3745, 6240], 4),\n",
       " ([2173, 2145, 11891], 4),\n",
       " ([2293, 7722, 13268], 5),\n",
       " ([8739, 13012, 15174], 5),\n",
       " ([24970, 2717, 21159], 4),\n",
       " ([2152, 2380, 2181], 4),\n",
       " ([2056, 2171, 19021, 2072], 5),\n",
       " ([2307, 2092, 12087, 2173], 4),\n",
       " ([3509, 10844, 2307, 3976], 4),\n",
       " ([2190, 8840, 11266, 16030], 5),\n",
       " ([2204, 2052, 16755, 2767], 5),\n",
       " ([2644, 8254, 2278, 2330], 4),\n",
       " ([2204, 8066, 2192, 2852], 5),\n",
       " ([2052, 2152, 3669, 16755], 4),\n",
       " ([2293, 2471, 8840, 11266], 2),\n",
       " ([2717, 21159, 14980, 7140], 5),\n",
       " ([8285, 2213, 5955, 2203], 4),\n",
       " ([15212, 4385, 3972, 28775], 3),\n",
       " ([2052, 2196, 2412, 2175], 5),\n",
       " ([3246, 2330, 2521, 6167], 1),\n",
       " ([2204, 2051, 6240, 4840], 3),\n",
       " ([2393, 2354, 2149, 2051], 1),\n",
       " ([10557, 3013, 2202, 27263], 5),\n",
       " ([2172, 2488, 2197, 3942], 5),\n",
       " ([2204, 2172, 2488, 1052], 1),\n",
       " ([2293, 4748, 2953, 2173], 4),\n",
       " ([3256, 6949, 25933, 2480], 1),\n",
       " ([2128, 7849, 28940, 2365], 3),\n",
       " ([4687, 2293, 3393, 2818], 4),\n",
       " ([6090, 5498, 4687, 4497], 3),\n",
       " ([9805, 7382, 2072, 2066], 5),\n",
       " ([2307, 2173, 3942, 7954], 5),\n",
       " ([5507, 19646, 5156, 5247], 4),\n",
       " ([5660, 3819, 16755, 2173], 4),\n",
       " ([2330, 3347, 2204, 2051], 5),\n",
       " ([2833, 2190, 2833, 4761], 4),\n",
       " ([1037, 9491, 12183, 4761], 4),\n",
       " ([2307, 5292, 9397, 2072], 4),\n",
       " ([2632, 4576, 7438, 2092], 4),\n",
       " ([6865, 2147, 4569, 2173], 4),\n",
       " ([25933, 2480, 2204, 2833], 5),\n",
       " ([3178, 29278, 13012, 2131], 1),\n",
       " ([24582, 2072, 11937, 2173], 5),\n",
       " ([2208, 2485, 3786, 3976], 5),\n",
       " ([12486, 11642, 3442, 2190], 3),\n",
       " ([4550, 17738, 2615, 2126], 5),\n",
       " ([3976, 2175, 2067, 2153], 1),\n",
       " ([2214, 4827, 9805, 2213], 5),\n",
       " ([2488, 2173, 2214, 2237], 5),\n",
       " ([2767, 3669, 5684, 4183], 5),\n",
       " ([2307, 27218, 2891, 27921], 4),\n",
       " ([2190, 10077, 25022, 3775], 4),\n",
       " ([3393, 5073, 14262, 7903], 5),\n",
       " ([2000, 4904, 8991, 2099], 2),\n",
       " ([7146, 4010, 9805, 2213], 4),\n",
       " ([3653, 6916, 2204, 10733], 5),\n",
       " ([3835, 3962, 2272, 2767], 3),\n",
       " ([3398, 2307, 2465, 4067], 5),\n",
       " ([5959, 13675, 5243, 29068], 3),\n",
       " ([3393, 7668, 9765, 24970], 5),\n",
       " ([24970, 2833, 5023, 17070], 5),\n",
       " ([5939, 24330, 2204, 2833], 5),\n",
       " ([2344, 18178, 2229, 19116], 4),\n",
       " ([2342, 1056, 15472, 2295], 5),\n",
       " ([2908, 2091, 19466, 3435], 3),\n",
       " ([2732, 12731, 2480, 12656], 5),\n",
       " ([15180, 25426, 18074, 22542], 3),\n",
       " ([3653, 6916, 4365, 2204], 5),\n",
       " ([2057, 22499, 2213, 3696], 5),\n",
       " ([2345, 19723, 6072, 12069], 3),\n",
       " ([9436, 2594, 5313, 2204], 5),\n",
       " ([15180, 25426, 16755, 2009], 5),\n",
       " ([2632, 4576, 2175, 2173], 2),\n",
       " ([2247, 2395, 14980, 7140], 3),\n",
       " ([2307, 2173, 3602, 12183], 5),\n",
       " ([2190, 3066, 2237, 4171], 5),\n",
       " ([2265, 3280, 2057, 5339], 3),\n",
       " ([2204, 2152, 3669, 16755], 3),\n",
       " ([3095, 2130, 4711, 3524], 5),\n",
       " ([2066, 2193, 2131, 2126], 5),\n",
       " ([2173, 3618, 14262, 2615], 5),\n",
       " ([2204, 3256, 2522, 16020], 4),\n",
       " ([2165, 2307, 2729, 2149], 5),\n",
       " ([6861, 15174, 8067, 2480], 3),\n",
       " ([2173, 2566, 2386, 2485], 5),\n",
       " ([5959, 1054, 4048, 2173], 3),\n",
       " ([27427, 12848, 3593, 16284], 2),\n",
       " ([9518, 2288, 2980, 2300], 4),\n",
       " ([5116, 3260, 2717, 21159], 4),\n",
       " ([2036, 26202, 16033, 2361], 1),\n",
       " ([12486, 2204, 2293, 2173], 3),\n",
       " ([2217, 2237, 2172, 2488], 1),\n",
       " ([2224, 2833, 11132, 2272], 1),\n",
       " ([4487, 12693, 2278, 3309], 2),\n",
       " ([2293, 7438, 2157, 2173], 5),\n",
       " ([2173, 3100, 9544, 5443], 4),\n",
       " ([24970, 14262, 7903, 6397], 5),\n",
       " ([2228, 2151, 2705, 2066], 4),\n",
       " ([11972, 10147, 9779, 2361], 1),\n",
       " ([2360, 2438, 24480, 2192], 5),\n",
       " ([3435, 3514, 11132, 2469], 1),\n",
       " ([3095, 2190, 8513, 4665], 5),\n",
       " ([2204, 8066, 4067, 2067], 4),\n",
       " ([2293, 2572, 15599, 2278], 3),\n",
       " ([2204, 9522, 13844, 2092], 5),\n",
       " ([15653, 2140, 3972, 28775], 4),\n",
       " ([2349, 12726, 3095, 2266], 4),\n",
       " ([2175, 4497, 2293, 2009], 4),\n",
       " ([9518, 2131, 2307, 14171], 4),\n",
       " ([2066, 8840, 11266, 11891], 1),\n",
       " ([2173, 2190, 2191, 16823], 5),\n",
       " ([24970, 2717, 21159, 10026], 4),\n",
       " ([2190, 2833, 2919, 2593], 5),\n",
       " ([2773, 1055, 25083, 2906], 4),\n",
       " ([17748, 2665, 14068, 2600], 1),\n",
       " ([3972, 28775, 2067, 2709], 2),\n",
       " ([2821, 3398, 3786, 2009], 5),\n",
       " ([2039, 2850, 2102, 2485], 1),\n",
       " ([3972, 28775, 6517, 2485], 4),\n",
       " ([4664, 3760, 5987, 2204], 4),\n",
       " ([2852, 2307, 16030, 4845], 3),\n",
       " ([15180, 25426, 10818, 7276], 5),\n",
       " ([2204, 1043, 12541, 2080], 3),\n",
       " ([14418, 10199, 24593, 2088], 1),\n",
       " ([2204, 2204, 24570, 2205], 5),\n",
       " ([13012, 2417, 15180, 25426], 5),\n",
       " ([2204, 7276, 2253, 3524], 5),\n",
       " ([3435, 2767, 3669, 2709], 4),\n",
       " ([10131, 2566, 14891, 2651], 5),\n",
       " ([2019, 14573, 28305, 13012], 5),\n",
       " ([2190, 2717, 21159, 4339, 10172], 1),\n",
       " ([2833, 3291, 28249, 6900, 2072], 4),\n",
       " ([2228, 7570, 2271, 2735, 3347], 5),\n",
       " ([16755, 2066, 4840, 18414, 2594], 5),\n",
       " ([5356, 3771, 2036, 2204, 2298], 5),\n",
       " ([2843, 2488, 5987, 2173, 2066], 2),\n",
       " ([2051, 2204, 2175, 2173, 2833], 5),\n",
       " ([4248, 2126, 23801, 11971, 2126], 5),\n",
       " ([3335, 18414, 2594, 2718, 3962], 5),\n",
       " ([17704, 20857, 8038, 2213, 2190], 5),\n",
       " ([3460, 16755, 2151, 2239, 2113], 5),\n",
       " ([2061, 18752, 3308, 3319, 3025], 1),\n",
       " ([2344, 4942, 2632, 4576, 2204], 5),\n",
       " ([2833, 7929, 2307, 2126, 2488], 4),\n",
       " ([4840, 5404, 2307, 2066, 2009], 3),\n",
       " ([14262, 7903, 17727, 8586, 2278], 1),\n",
       " ([2609, 20228, 2226, 1055, 25083], 3),\n",
       " ([17111, 2080, 3280, 2005, 2293], 2),\n",
       " ([2288, 3573, 2485, 2360, 2485], 1),\n",
       " ([3105, 7438, 2066, 5749, 7559], 4),\n",
       " ([2342, 2113, 2173, 4521, 3891], 5),\n",
       " ([2067, 2307, 4654, 4842, 2072], 1),\n",
       " ([2293, 16480, 25778, 3104, 26011], 5),\n",
       " ([16510, 2204, 2288, 2204, 6350], 4),\n",
       " ([21934, 24759, 5371, 21628, 2140], 5),\n",
       " ([5684, 4183, 2173, 6014, 2980], 3),\n",
       " ([2051, 4569, 2342, 3819, 2067], 4),\n",
       " ([2298, 2152, 3669, 16755, 2068], 5),\n",
       " ([2253, 2307, 17935, 3775, 3962], 2),\n",
       " ([3835, 8840, 11266, 3835, 19459], 3),\n",
       " ([2397, 2919, 24608, 2105, 2051], 5),\n",
       " ([3335, 10861, 3736, 4305, 4571], 4),\n",
       " ([2307, 2173, 3671, 6350, 15942], 5),\n",
       " ([2204, 2173, 4392, 3524, 24240], 5),\n",
       " ([2387, 9587, 2271, 2448, 3829], 4),\n",
       " ([2175, 2085, 5002, 3942, 2146], 4),\n",
       " ([2293, 4521, 16755, 7232, 24570], 4),\n",
       " ([15708, 2173, 3942, 2307, 5592], 5),\n",
       " ([2190, 2173, 2379, 7276, 2092], 2),\n",
       " ([2379, 4761, 13012, 2612, 2593], 3),\n",
       " ([2488, 2085, 5886, 2379, 2204], 4),\n",
       " ([2187, 3609, 3653, 6916, 17026], 5),\n",
       " ([2507, 2732, 3937, 2147, 2627], 3),\n",
       " ([2173, 8246, 3972, 12848, 2627], 5),\n",
       " ([2204, 4761, 7541, 4942, 2131], 5),\n",
       " ([2632, 4576, 2190, 2293, 2173], 4),\n",
       " ([2139, 14808, 5245, 4031, 2017], 1),\n",
       " ([2293, 15174, 2152, 3669, 16755], 1),\n",
       " ([2113, 3573, 3976, 3465, 3769], 4),\n",
       " ([2344, 4605, 2130, 2440, 8257], 5),\n",
       " ([2502, 4920, 2813, 2204, 2833], 5),\n",
       " ([2131, 10036, 4355, 4435, 4933], 5),\n",
       " ([3786, 18178, 2229, 10733, 2569], 3),\n",
       " ([1037, 2188, 2175, 14865, 3501], 4),\n",
       " ([21934, 24759, 8254, 2172, 2050], 4),\n",
       " ([13366, 5498, 2102, 2272, 2067], 4),\n",
       " ([4658, 4145, 2047, 2287, 2833], 4),\n",
       " ([3037, 21877, 7361, 2140, 3422], 5),\n",
       " ([6752, 2202, 2344, 2717, 21159], 5),\n",
       " ([2188, 5660, 14262, 7903, 12656], 3),\n",
       " ([5959, 6350, 2052, 16755, 13012], 2),\n",
       " ([2051, 4487, 3736, 9397, 25785], 3),\n",
       " ([4239, 1037, 8872, 17301, 2595], 5),\n",
       " ([2293, 2173, 2293, 2307, 2079], 4),\n",
       " ([3962, 2006, 2105, 2307, 2051], 3),\n",
       " ([2173, 1037, 7987, 4609, 2818], 4),\n",
       " ([2853, 2307, 2152, 3669, 16755], 5),\n",
       " ([2131, 2438, 2173, 2293, 2051], 4),\n",
       " ([3095, 8331, 14262, 7903, 10026], 2),\n",
       " ([2081, 2514, 2113, 23115, 4058], 4),\n",
       " ([5514, 6082, 4638, 2378, 16823], 5),\n",
       " ([2293, 15610, 3524, 2272, 2067], 1),\n",
       " ([15180, 25426, 2665, 2272, 2067], 1),\n",
       " ([29461, 14753, 14262, 7903, 9491], 4),\n",
       " ([2773, 7975, 27263, 11266, 2050], 5),\n",
       " ([2556, 9841, 8235, 4569, 2130], 1),\n",
       " ([4189, 3976, 2767, 3669, 3095], 5),\n",
       " ([2190, 2173, 4952, 2334, 2189], 4),\n",
       " ([2124, 2047, 6095, 2655, 16823], 5),\n",
       " ([10424, 2072, 2307, 6073, 7929], 4),\n",
       " ([8676, 2833, 18565, 11350, 2204], 4),\n",
       " ([3435, 7481, 9518, 2177, 8081], 4),\n",
       " ([2190, 2130, 2485, 25933, 2480], 5),\n",
       " ([2190, 11687, 2175, 2131, 2009], 5),\n",
       " ([24970, 2415, 17603, 4017, 3836], 5),\n",
       " ([3835, 3095, 2152, 3669, 16755], 5),\n",
       " ([2833, 13012, 2030, 5654, 20593], 5),\n",
       " ([5684, 4183, 26509, 24970, 24570], 4),\n",
       " ([3972, 28775, 2342, 2360, 2062], 2),\n",
       " ([4070, 2182, 2196, 2224, 2068], 4),\n",
       " ([5404, 2166, 2064, 2025, 2488], 1),\n",
       " ([8945, 7068, 11392, 2072, 24970], 5),\n",
       " ([2564, 2307, 3105, 3114, 3465], 3),\n",
       " ([2344, 13558, 2197, 2051, 2344], 5),\n",
       " ([2234, 8081, 3042, 2188, 6209], 3),\n",
       " ([7046, 25933, 2480, 4392, 2190], 4),\n",
       " ([5684, 4183, 4511, 2235, 5127], 5),\n",
       " ([2066, 2461, 9065, 2204, 21475], 5),\n",
       " ([2092, 4518, 12666, 2063, 2393], 5),\n",
       " ([2464, 7731, 2265, 5684, 4183], 2),\n",
       " ([2190, 5404, 7276, 18720, 2232], 4),\n",
       " ([5404, 2215, 2833, 2295, 7929], 5),\n",
       " ([3819, 3669, 4748, 2157, 5926], 5),\n",
       " ([3435, 2911, 8875, 2298, 2307], 2),\n",
       " ([2868, 7098, 3669, 4067, 2852], 5),\n",
       " ([2033, 2307, 7661, 14262, 7903], 2),\n",
       " ([2773, 1042, 1047, 10216, 2293], 5),\n",
       " ([2307, 8840, 11266, 2293, 2272], 4),\n",
       " ([2025, 2232, 2460, 25933, 2480], 3),\n",
       " ([2452, 5572, 5448, 2228, 2488], 2),\n",
       " ([4895, 21877, 2226, 24188, 14736], 1),\n",
       " ([11234, 17710, 10649, 6279, 4485], 5),\n",
       " ([2833, 4840, 7852, 2234, 17428], 2),\n",
       " ([2276, 2377, 2189, 2066, 2276], 5),\n",
       " ([2980, 7169, 2835, 3298, 2083], 5),\n",
       " ([2204, 4392, 3984, 3775, 2213], 3),\n",
       " ([2165, 3899, 2051, 2307, 3105], 5),\n",
       " ([4067, 9530, 7629, 2226, 5776], 5),\n",
       " ([2204, 2293, 2204, 14262, 7903], 1),\n",
       " ([10514, 6182, 2562, 2131, 2488], 1),\n",
       " ([2217, 9841, 3272, 10424, 2072], 4),\n",
       " ([4897, 13433, 3600, 8223, 2368], 2),\n",
       " ([14262, 7903, 3298, 27046, 3976], 4),\n",
       " ([2293, 2482, 2265, 2404, 2006], 5),\n",
       " ([6900, 2072, 3543, 2151, 2705], 2),\n",
       " ([3835, 25545, 20432, 2438, 2056], 5),\n",
       " ([2307, 14262, 7903, 2307, 3105], 3),\n",
       " ([2655, 2765, 24970, 15512, 2482], 5),\n",
       " ([12075, 10497, 16755, 2272, 2182], 4),\n",
       " ([2092, 2131, 5305, 3280, 4175], 5),\n",
       " ([2489, 17727, 12298, 2307, 3066], 5),\n",
       " ([2632, 4576, 2393, 2293, 2173], 5),\n",
       " ([2474, 4012, 8524, 3565, 3565], 4),\n",
       " ([2307, 2173, 15890, 4248, 6265], 5),\n",
       " ([2066, 2190, 2978, 8501, 3962], 4),\n",
       " ([2442, 2036, 16755, 11867, 28775], 3),\n",
       " ([2204, 2173, 13774, 21877, 4305], 3),\n",
       " ([18968, 2081, 3959, 2272, 2995], 4),\n",
       " ([2190, 10047, 23041, 8662, 2237], 4),\n",
       " ([2190, 22489, 4840, 2843, 2327], 4),\n",
       " ([2307, 4654, 4842, 2072, 2852], 2),\n",
       " ([2190, 15653, 2140, 2843, 20130], 5),\n",
       " ([3711, 2173, 2330, 6265, 2085], 3),\n",
       " ([2307, 7276, 8416, 2092, 5812], 3),\n",
       " ([2190, 15890, 10424, 2072, 5968], 2),\n",
       " ([2190, 2190, 4067, 3124, 2600], 5),\n",
       " ([3499, 14262, 2615, 6544, 2375], 4),\n",
       " ([4078, 23270, 2139, 16307, 4592], 5),\n",
       " ([3280, 3246, 2175, 2502, 3712], 5),\n",
       " ([2190, 10733, 3358, 2225, 6278], 3),\n",
       " ([2190, 10733, 6708, 17752, 2056], 5),\n",
       " ([19349, 4664, 10364, 3393, 5431], 5),\n",
       " ([22512, 2425, 2833, 8676, 2307], 5),\n",
       " ([2066, 6260, 2080, 2806, 7954], 4),\n",
       " ([2293, 2014, 4067, 14262, 7903], 4),\n",
       " ([4067, 2307, 3460, 2191, 3255], 1),\n",
       " ([2632, 4576, 2330, 2833, 2307], 3),\n",
       " ([4121, 11851, 20548, 12226, 2489], 5),\n",
       " ([21100, 3593, 2181, 3819, 4845], 5),\n",
       " ([2293, 2000, 16917, 2050, 16521], 1),\n",
       " ([10424, 8591, 2307, 2606, 12690], 1),\n",
       " ([2204, 5189, 2316, 2113, 3043], 5),\n",
       " ([4067, 2393, 7570, 13102, 4183], 3),\n",
       " ([15161, 8046, 27218, 2891, 27921], 5),\n",
       " ([10047, 2148, 2036, 2613, 3066], 5),\n",
       " ([2190, 10514, 6182, 20877, 2483], 3),\n",
       " ([2919, 2146, 4062, 6592, 2202], 5),\n",
       " ([10017, 2173, 2204, 21500, 10610], 3),\n",
       " ([28359, 3309, 7110, 2102, 2028], 1),\n",
       " ([24799, 24511, 27605, 2293, 2173], 5),\n",
       " ([2066, 7541, 2131, 2919, 2204], 1),\n",
       " ([3422, 4060, 4013, 8566, 2278], 5),\n",
       " ([2152, 3669, 16755, 2717, 21159], 5),\n",
       " ([2081, 2514, 7216, 3095, 2307], 3),\n",
       " ([13366, 5498, 2102, 2442, 2175], 4),\n",
       " ([2193, 2095, 3283, 2204, 3105], 5),\n",
       " ([2204, 10017, 2833, 24799, 2204], 4),\n",
       " ([2409, 15805, 2344, 3477, 2062], 5),\n",
       " ([5404, 3422, 2338, 10665, 2173], 1),\n",
       " ([2393, 3042, 2767, 2293, 6546], 4),\n",
       " ([2204, 7276, 3095, 15180, 25426], 5),\n",
       " ([2172, 2488, 3124, 2488, 2488], 3),\n",
       " ([25933, 2480, 11345, 3335, 3942], 4),\n",
       " ([2204, 3976, 2717, 21159, 3028], 1),\n",
       " ([3835, 2833, 2204, 3976, 2204], 5),\n",
       " ([5507, 19646, 3976, 2100, 5987], 5),\n",
       " ([2131, 1996, 2147, 2296, 2705], 5),\n",
       " ([2190, 14262, 7903, 2718, 3335], 4),\n",
       " ([5474, 2072, 10930, 27390, 2102], 5),\n",
       " ([3972, 28775, 4438, 5610, 6240], 3),\n",
       " ([3972, 28775, 2833, 2442, 13012], 5),\n",
       " ([2190, 2606, 2358, 8516, 2923], 5),\n",
       " ([7842, 6767, 5397, 5602, 3802], 5),\n",
       " ([2190, 2272, 2204, 3105, 3124], 5),\n",
       " ([12666, 2063, 9680, 6442, 3857], 5),\n",
       " ([2190, 2717, 21159, 2018, 24970], 1),\n",
       " ([2543, 10733, 24970, 4664, 2502], 1),\n",
       " ([8288, 24759, 4630, 15180, 25426], 4),\n",
       " ([4895, 11084, 2128, 21163, 2078], 5),\n",
       " ([11519, 6265, 23621, 16521, 2930], 5),\n",
       " ([2272, 2067, 2132, 2067, 2188], 4),\n",
       " ([3095, 2785, 2457, 8780, 2226], 3),\n",
       " ([2173, 4067, 6592, 2173, 2767], 4),\n",
       " ([8241, 2424, 7570, 2271, 2067], 5),\n",
       " ([2579, 5247, 2051, 2240, 4497], 5),\n",
       " ([2051, 6265, 2307, 2833, 5407], 5),\n",
       " ([4067, 24970, 7661, 14262, 7903], 4),\n",
       " ([2522, 16020, 2190, 2293, 7668], 2),\n",
       " ([4840, 6546, 4189, 3669, 3976], 1),\n",
       " ([2327, 2035, 2035, 6633, 8665], 4),\n",
       " ([4276, 2175, 3246, 2025, 5670], 4),\n",
       " ([2190, 2717, 3126, 2995, 2806], 2),\n",
       " ([19395, 4013, 3676, 16558, 2190], 5),\n",
       " ([3653, 6916, 11080, 2072, 12043], 3),\n",
       " ([18651, 18178, 2229, 25933, 2480], 5),\n",
       " ([4062, 2051, 4536, 3199, 2307], 1),\n",
       " ([14262, 7903, 17727, 8586, 2278], 3),\n",
       " ([2202, 9220, 9090, 26509, 2204], 5),\n",
       " ([7570, 18752, 16558, 28667, 8462, 4859], 5),\n",
       " ([2307, 2569, 13877, 15180, 25426, 2028], 5),\n",
       " ([2293, 2173, 14262, 2615, 6350, 2154], 5),\n",
       " ([2307, 2235, 9047, 2833, 4392, 2569], 5),\n",
       " ([2307, 2147, 2007, 9518, 4067, 3124], 4),\n",
       " ([4687, 2417, 14068, 5785, 2204, 2058], 5),\n",
       " ([2253, 5024, 2833, 15180, 25426, 5404], 2),\n",
       " ([26509, 7367, 21559, 6014, 26509, 2485], 4),\n",
       " ([2693, 9781, 27035, 2190, 2412, 2018], 5),\n",
       " ([2518, 2173, 2175, 21025, 7382, 6799], 5),\n",
       " ([8875, 2632, 4576, 3942, 2173, 2181], 4),\n",
       " ([2474, 10623, 7276, 5572, 2181, 3006], 3),\n",
       " ([21209, 2105, 13366, 5498, 2102, 2442], 5),\n",
       " ([2272, 2411, 2377, 14957, 2307, 2173], 4),\n",
       " ([2735, 18015, 2072, 26735, 3006, 18201], 5),\n",
       " ([2204, 2307, 2994, 7601, 2408, 2395], 1),\n",
       " ([2307, 10733, 3972, 12848, 13012, 3066], 4),\n",
       " ([2632, 4576, 3976, 28017, 9956, 3565], 4),\n",
       " ([2124, 3358, 13803, 22861, 4160, 15890], 4),\n",
       " ([10036, 2204, 6904, 3726, 2717, 21159], 4),\n",
       " ([2307, 2217, 2067, 7367, 6299, 2051], 2),\n",
       " ([9231, 10264, 5470, 3335, 16215, 2072], 5),\n",
       " ([10887, 9861, 4558, 2769, 2131, 2765], 4),\n",
       " ([4658, 2173, 2424, 2396, 6865, 2767], 1),\n",
       " ([14380, 4215, 2175, 2063, 3819, 3684], 5),\n",
       " ([2190, 3524, 2240, 2131, 4656, 2072], 5),\n",
       " ([3524, 1055, 24703, 10814, 2668, 4009], 1),\n",
       " ([2307, 4306, 7254, 2835, 10017, 2833], 1),\n",
       " ([27218, 2891, 27921, 3835, 24570, 24970], 5),\n",
       " ([2190, 2833, 2412, 4299, 2272, 2574], 3),\n",
       " ([2448, 3328, 2613, 15775, 12179, 2290], 5),\n",
       " ([4942, 15180, 25426, 2152, 3669, 16755], 5),\n",
       " ([3942, 13075, 3695, 2226, 8840, 11266], 4),\n",
       " ([2307, 2173, 8676, 24209, 11475, 3775], 5),\n",
       " ([4942, 2052, 16755, 2173, 2151, 2239], 4),\n",
       " ([11333, 2145, 11519, 2173, 6865, 2041], 1),\n",
       " ([5156, 2717, 21159, 24570, 5096, 2833], 4),\n",
       " ([3095, 2293, 2009, 4067, 15125, 14083], 1),\n",
       " ([2919, 2919, 2769, 5533, 3954, 2801], 5),\n",
       " ([5684, 4183, 2173, 2393, 2561, 12074], 3),\n",
       " ([2154, 2190, 2088, 4012, 22327, 4183], 4),\n",
       " ([2307, 2052, 13366, 5498, 2102, 2709], 5),\n",
       " ([2342, 2307, 2717, 21159, 2066, 2028], 4),\n",
       " ([2307, 2833, 4521, 2131, 9212, 2278], 3),\n",
       " ([2204, 4933, 4550, 2173, 2833, 8676], 3),\n",
       " ([13012, 11937, 3367, 18178, 7712, 3147], 5),\n",
       " ([2485, 2128, 26915, 2145, 2128, 26915], 5),\n",
       " ([2613, 3669, 2048, 23348, 26760, 2884], 5),\n",
       " ([2307, 2707, 5353, 4067, 2474, 15942], 5),\n",
       " ([13012, 12927, 5699, 5610, 2100, 4933], 5),\n",
       " ([2435, 6513, 4308, 3291, 5723, 2305], 5),\n",
       " ([3626, 3272, 8242, 2081, 11642, 2293], 5),\n",
       " ([3869, 11937, 3597, 2600, 2307, 24570], 4),\n",
       " ([2173, 2485, 16360, 2721, 2278, 3954], 3),\n",
       " ([3095, 4067, 2202, 2729, 10818, 2342], 1),\n",
       " ([4130, 3388, 2330, 2123, 4904, 20342], 5),\n",
       " ([6904, 8569, 2140, 2393, 3221, 10014], 5),\n",
       " ([2293, 2173, 2190, 6240, 3013, 16755], 5),\n",
       " ([2833, 2204, 2711, 4982, 2833, 7929], 5),\n",
       " ([3565, 4569, 2152, 3669, 16755, 2287], 5),\n",
       " ([2228, 2190, 4632, 11589, 2717, 21159], 4),\n",
       " ([2450, 2393, 3114, 2165, 2146, 3160], 4),\n",
       " ([2412, 2031, 10047, 3959, 2157, 2085], 5),\n",
       " ([2204, 6735, 2131, 16823, 2203, 9413], 5),\n",
       " ([2165, 2767, 3669, 2307, 4536, 3199], 5),\n",
       " ([25933, 2480, 2190, 2179, 6300, 14277], 4),\n",
       " ([2293, 2182, 20568, 3819, 9378, 2205], 1),\n",
       " ([2684, 2052, 16755, 2173, 2151, 2239], 1),\n",
       " ([2307, 4664, 7046, 2507, 2173, 2732], 4),\n",
       " ([9378, 6271, 2852, 2072, 29490, 2307], 1),\n",
       " ([3714, 5785, 9841, 2613, 3669, 2204], 4),\n",
       " ([7708, 2980, 16480, 25778, 6300, 22512], 5),\n",
       " ([3100, 10887, 3524, 3095, 12824, 3524], 5),\n",
       " ([2145, 16755, 3566, 3769, 2717, 21159], 5),\n",
       " ([2442, 2240, 2146, 3524, 10140, 2173], 3),\n",
       " ([2307, 9450, 4687, 2465, 8984, 3976], 3),\n",
       " ([2173, 5660, 2072, 5699, 5660, 2072], 3),\n",
       " ([2058, 2389, 2307, 14262, 7903, 4189], 2),\n",
       " ([16755, 2334, 4487, 3736, 9397, 25785], 1),\n",
       " ([3835, 5154, 24951, 2290, 2136, 21688], 1),\n",
       " ([5225, 2126, 2938, 2165, 2360, 13362], 5),\n",
       " ([2131, 9781, 20209, 4063, 3480, 4426], 5),\n",
       " ([13268, 10166, 25933, 2480, 2187, 2514], 5),\n",
       " ([4276, 3942, 6073, 2131, 4330, 2072], 4),\n",
       " ([2457, 10448, 3802, 2572, 15599, 2278], 5),\n",
       " ([10223, 3070, 2485, 16688, 2579, 2173], 5),\n",
       " ([4569, 3490, 3041, 3319, 3972, 3388], 4),\n",
       " ([20857, 6090, 5654, 8676, 2300, 2067], 1),\n",
       " ([4962, 2099, 9544, 3653, 6916, 2204], 1),\n",
       " ([26927, 3683, 19666, 2072, 20649, 2072], 5),\n",
       " ([2202, 2444, 5116, 2345, 2191, 2182], 3),\n",
       " ([1835, 100, 100, 1957, 1744, 100], 4),\n",
       " ([2173, 2485, 2253, 2224, 2341, 3844], 5),\n",
       " ([25933, 2480, 4921, 2063, 2272, 2197], 4),\n",
       " ([2307, 2173, 2448, 3113, 2767, 2175], 3),\n",
       " ([3835, 27218, 2891, 27921, 4067, 8241], 3),\n",
       " ([11582, 3976, 6265, 4596, 2833, 2204], 4),\n",
       " ([4067, 11132, 3514, 2625, 2067, 2153], 5),\n",
       " ([3565, 2860, 13366, 5498, 2102, 2709], 5),\n",
       " ([2833, 3972, 28775, 5507, 19646, 3976], 1),\n",
       " ([8241, 2081, 4654, 4842, 2072, 3835], 4),\n",
       " ([15180, 25426, 2833, 14262, 7903, 16755], 4),\n",
       " ([3105, 2204, 3976, 2205, 2655, 3291], 1),\n",
       " ([4687, 2173, 4687, 3836, 3835, 9823], 5),\n",
       " ([2190, 2806, 8616, 16755, 7842, 14194], 4),\n",
       " ([2488, 10514, 6182, 4550, 4840, 8676], 2),\n",
       " ([2204, 2833, 2502, 4664, 3114, 3976], 2),\n",
       " ([2165, 12183, 2187, 2253, 2190, 2293], 5),\n",
       " ([2190, 3942, 2296, 3775, 2213, 2237], 1),\n",
       " ([13366, 5498, 2102, 2442, 2175, 2173], 5),\n",
       " ([2047, 4182, 21296, 4962, 2099, 4569], 4),\n",
       " ([2190, 2173, 2175, 8808, 13473, 4817], 4),\n",
       " ([2190, 3869, 6293, 9090, 5116, 3524], 1),\n",
       " ([5959, 10733, 12570, 2613, 3669, 5959], 3),\n",
       " ([3809, 2644, 2157, 2131, 14704, 13012], 4),\n",
       " ([2204, 2833, 2204, 18151, 2278, 2272], 1),\n",
       " ([5580, 2067, 5959, 2489, 9090, 26509], 1),\n",
       " ([3972, 4509, 6350, 3335, 4521, 2067], 5),\n",
       " ([2344, 8676, 2204, 2196, 2919, 7954], 4),\n",
       " ([2052, 4013, 3676, 16558, 14894, 4248], 5),\n",
       " ([3976, 8369, 16755, 2175, 3347, 2569], 5),\n",
       " ([15180, 25426, 2307, 7661, 14262, 7903], 5),\n",
       " ([2047, 3954, 2001, 2102, 24471, 2769], 4),\n",
       " ([2173, 15180, 25426, 2626, 2650, 2009], 5),\n",
       " ([2307, 2092, 2152, 3669, 16755, 2067], 4),\n",
       " ([11234, 11090, 2521, 2152, 3669, 16755], 5),\n",
       " ([6350, 2203, 6265, 4088, 2051, 14017], 3),\n",
       " ([13366, 5498, 2102, 16755, 2490, 2334], 5),\n",
       " ([3899, 2293, 6904, 6895, 2140, 3095], 5),\n",
       " ([24951, 2290, 3786, 2562, 2204, 2147], 4),\n",
       " ([2711, 2729, 2152, 3669, 16755, 2852], 4),\n",
       " ([2190, 2412, 2072, 2051, 3543, 2655], 5),\n",
       " ([16360, 2721, 2278, 23801, 2072, 3178], 4),\n",
       " ([2204, 10733, 7842, 10383, 2290, 18565], 4),\n",
       " ([3298, 6708, 2156, 2342, 2360, 2062], 1),\n",
       " ([2110, 2485, 5138, 7661, 1059, 24475], 5),\n",
       " ([4276, 3524, 18064, 5356, 27218, 2609], 3),\n",
       " ([2190, 24501, 8162, 2278, 2110, 3269], 5),\n",
       " ([25933, 2480, 27090, 2812, 2293, 2173], 2),\n",
       " ([1037, 2173, 2365, 7929, 20228, 2226], 4),\n",
       " ([2215, 2175, 2252, 2066, 5225, 2613], 4),\n",
       " ([2171, 11132, 21442, 8661, 10521, 2391], 4),\n",
       " ([2293, 2173, 9483, 2307, 4031, 13268], 3),\n",
       " ([2066, 2066, 3671, 1038, 3270, 4478], 4),\n",
       " ([2204, 3976, 29602, 2469, 2175, 2067], 2),\n",
       " ([2081, 2514, 2569, 8241, 2130, 2488], 4),\n",
       " ([28249, 3242, 4133, 3524, 2611, 4497], 4),\n",
       " ([26568, 16558, 2833, 2131, 2047, 5660], 4),\n",
       " ([2307, 7099, 2099, 3819, 2202, 2147], 4),\n",
       " ([14262, 7903, 2204, 2833, 3113, 3347], 1),\n",
       " ([4067, 6816, 2067, 2574, 2190, 2237], 5),\n",
       " ([2066, 7276, 8416, 10818, 2182, 2919], 4),\n",
       " ([2613, 3669, 2307, 2293, 2272, 2067], 4),\n",
       " ([2173, 2204, 3524, 4133, 2833, 2307], 3),\n",
       " ([15180, 25426, 4638, 2041, 12486, 2307], 4),\n",
       " ([5470, 10230, 2102, 6265, 2307, 3976], 5),\n",
       " ([5593, 2307, 2717, 21159, 2921, 4550], 5),\n",
       " ([2089, 3524, 2131, 21628, 2140, 2759], 5),\n",
       " ([4013, 3676, 16558, 2190, 2833, 6278], 5),\n",
       " ([3677, 3835, 2833, 2307, 2067, 2574], 3),\n",
       " ([3902, 2072, 12533, 4012, 26569, 8145], 5),\n",
       " ([2047, 5684, 4183, 2717, 21159, 2330], 4),\n",
       " ([11033, 2191, 4138, 2360, 2172, 3309], 3),\n",
       " ([10439, 3388, 25933, 2480, 2307, 3105], 3),\n",
       " ([4392, 3347, 2767, 3669, 12075, 10497], 4),\n",
       " ([4297, 5596, 7975, 11642, 2175, 2009], 4),\n",
       " ([2674, 2050, 14841, 6444, 2483, 2226], 4),\n",
       " ([8223, 2368, 2173, 2986, 3114, 3976], 5),\n",
       " ([15708, 2173, 4658, 3095, 13012, 2153], 4),\n",
       " ([10166, 9518, 17935, 3775, 3105, 8954], 5),\n",
       " ([2307, 14262, 7903, 3835, 14891, 2393], 2),\n",
       " ([5684, 4183, 2173, 4497, 2307, 3573], 5),\n",
       " ([2632, 4576, 2307, 2051, 2204, 2833], 1),\n",
       " ([2330, 2341, 2187, 2203, 2052, 2330], 1),\n",
       " ([21100, 5794, 2094, 3524, 2051, 2146], 5),\n",
       " ([18074, 22542, 13366, 5498, 2102, 2067], 4),\n",
       " ([3449, 2015, 2360, 4339, 2695, 2009], 3),\n",
       " ([2307, 2173, 9450, 6896, 2272, 2465], 5),\n",
       " ([2215, 2490, 4965, 2068, 2994, 2185], 4),\n",
       " ([4937, 11018, 3524, 7743, 7166, 2149], 1),\n",
       " ([5684, 4183, 6240, 22732, 14894, 4030], 5),\n",
       " ([6723, 11642, 3095, 2012, 6528, 2102], 4),\n",
       " ([4550, 3524, 3328, 4487, 12693, 2278], 1),\n",
       " ([2190, 2173, 2767, 3669, 24570, 2190], 3),\n",
       " ([100, 100, 1807, 100, 100, 13745], 5),\n",
       " ([2052, 16755, 2032, 3480, 13774, 3835], 4),\n",
       " ([3972, 28775, 2833, 24970, 14262, 7903], 1),\n",
       " ([2113, 2197, 2051, 5959, 2009, 2067], 4),\n",
       " ([2954, 2218, 2182, 5024, 4368, 3346], 4),\n",
       " ([2307, 2833, 4392, 2190, 18720, 2232], 1),\n",
       " ([2963, 2131, 2659, 13642, 29181, 16959], 1),\n",
       " ([2613, 3669, 2204, 7975, 14910, 2050], 4),\n",
       " ([13433, 2879, 2204, 20949, 3614, 2307], 5),\n",
       " ([2085, 3129, 3522, 2693, 2190, 2105], 2),\n",
       " ([2066, 3256, 6949, 8658, 3126, 4687], 1),\n",
       " ([2632, 4576, 2801, 2131, 5881, 2622], 5),\n",
       " ([13012, 2717, 21159, 2051, 2627, 16755], 4),\n",
       " ([10733, 4121, 2784, 9841, 7349, 2154], 1),\n",
       " ([2821, 2026, 2131, 2488, 2507, 2732], 5),\n",
       " ([2215, 2606, 3573, 4550, 3524, 2067], 1),\n",
       " ([2173, 2204, 2344, 3805, 2843, 2051], 2),\n",
       " ([27940, 6887, 2080, 4276, 3477, 2612], 4),\n",
       " ([3835, 10036, 2173, 26509, 15180, 25426], 5),\n",
       " ([2980, 2611, 2204, 2265, 3976, 2157], 4),\n",
       " ([2293, 2173, 2668, 2072, 9388, 3089], 5),\n",
       " ([4569, 3490, 2317, 5610, 2234, 4451], 4),\n",
       " ([2173, 2204, 2293, 2833, 6369, 4360], 5),\n",
       " ([2253, 2485, 2091, 2028, 2113, 4148], 5),\n",
       " ([10271, 10695, 3565, 16137, 7911, 14753], 1),\n",
       " ([27984, 2833, 4276, 5247, 2051, 3319], 2),\n",
       " ([12383, 16374, 12203, 2615, 21934, 24759], 4),\n",
       " ([2215, 8579, 7087, 16385, 2204, 2175], 5),\n",
       " ([2632, 4576, 2391, 14262, 7903, 2307], 4),\n",
       " ([3972, 4509, 2058, 18098, 15890, 4101], 3),\n",
       " ([12726, 13305, 2012, 3775, 8525, 2094], 3),\n",
       " ([3902, 2072, 2843, 7169, 7254, 2835], 5),\n",
       " ([2234, 2954, 8232, 4550, 2092, 5812], 5),\n",
       " ([4521, 2190, 2204, 2833, 10140, 15610], 4),\n",
       " ([2307, 3976, 2307, 7661, 14262, 7903], 1),\n",
       " ([25933, 2480, 3114, 3124, 4149, 5779], 2),\n",
       " ([2217, 10424, 2072, 4060, 2140, 6014], 3),\n",
       " ([5371, 2102, 2066, 2128, 4168, 14905], 4),\n",
       " ([4550, 2833, 2204, 2611, 2980, 2215], 5),\n",
       " ([8235, 4664, 2307, 2833, 2204, 3976], 5),\n",
       " ([10424, 2072, 2092, 2589, 15180, 25426], 3),\n",
       " ([7929, 2379, 4796, 1039, 18280, 3126], 5),\n",
       " ([2307, 8241, 2833, 2204, 2173, 5308], 2),\n",
       " ([1057, 2439, 7661, 2330, 2664, 2330], 5),\n",
       " ([2253, 2067, 2288, 27263, 18064, 2051], 2),\n",
       " ([27427, 13355, 2121, 2131, 3105, 2589], 5),\n",
       " ([2307, 10825, 2188, 12731, 14117, 2094], 5),\n",
       " ([2175, 2067, 2342, 2147, 2589, 16755], 4),\n",
       " ([2253, 3611, 10825, 2173, 3335, 9627], 5),\n",
       " ([5861, 3995, 2469, 2113, 2191, 2833], 5),\n",
       " ([4368, 3166, 2485, 2632, 16416, 4305], 5),\n",
       " ([2293, 2009, 24385, 2307, 12324, 7481], 5),\n",
       " ([3565, 2204, 2833, 4012, 19362, 3940], 3),\n",
       " ([2177, 2632, 4576, 2579, 2729, 2342], 1),\n",
       " ([4682, 2190, 10733, 2173, 2412, 4845], 2),\n",
       " ([2307, 2173, 2833, 2204, 13803, 4834], 5),\n",
       " ([2272, 2564, 2173, 2237, 2028, 3272], 5),\n",
       " ([11611, 18178, 2229, 7975, 6014, 3011], 5),\n",
       " ([3413, 2489, 14732, 24665, 10450, 2327], 5),\n",
       " ([2190, 13675, 10054, 22341, 2307, 3095], 1),\n",
       " ([2307, 5665, 2067, 4921, 2072, 2307], 3),\n",
       " ([2051, 27006, 2080, 2360, 2293, 2173], 5),\n",
       " ([2307, 3105, 2173, 5685, 2067, 2411], 5),\n",
       " ([7929, 2334, 3696, 2175, 2067, 2295], 1),\n",
       " ([2182, 13012, 23566, 2544, 2272, 2411], 5),\n",
       " ([2485, 2307, 2833, 3114, 3976, 2173], 5),\n",
       " ([2307, 3105, 5292, 9397, 2072, 4067], 1),\n",
       " ([13012, 2204, 2379, 2833, 2457, 4258], 4),\n",
       " ([7929, 4101, 4276, 14163, 12680, 2072], 4),\n",
       " ([2293, 2173, 2288, 6271, 5833, 2307], 4),\n",
       " ([15624, 2705, 23126, 24072, 2204, 8343], 1),\n",
       " ([3608, 11350, 7216, 2833, 5684, 4183], 4),\n",
       " ([2995, 10733, 2293, 2175, 2560, 2733], 5),\n",
       " ([2693, 5580, 3769, 4067, 13171, 2100], 1),\n",
       " ([2131, 3902, 2072, 2272, 4656, 2072], 4),\n",
       " ([11891, 2833, 17235, 3775, 2175, 2067], 5),\n",
       " ([2785, 4010, 2540, 9518, 2307, 2173], 1),\n",
       " ([12183, 10026, 2191, 2588, 5227, 24970], 4),\n",
       " ([2344, 2980, 9841, 2234, 17688, 2504], 5),\n",
       " ([2307, 2173, 2051, 11199, 2100, 3835], 4),\n",
       " ([2228, 2485, 2566, 2740, 3647, 3775], 1),\n",
       " ([2288, 23126, 24072, 2908, 26352, 5017], 4),\n",
       " ([2187, 2978, 4078, 4313, 2709, 2469], 5),\n",
       " ([3524, 17704, 2146, 2833, 4276, 3524], 1),\n",
       " ([2204, 2066, 3835, 2474, 5831, 2314], 5),\n",
       " ([2152, 3669, 16755, 2644, 2011, 2067], 3),\n",
       " ([3835, 25545, 9231, 2102, 11894, 6928], 5),\n",
       " ([2326, 2099, 2204, 2051, 3522, 2304], 5),\n",
       " ([9467, 2022, 28727, 2759, 2439, 11084], 5),\n",
       " ([3904, 4654, 4842, 2072, 2190, 2412], 2),\n",
       " ([10036, 2307, 2980, 7842, 14194, 2205], 5),\n",
       " ([3095, 4687, 7276, 4392, 3972, 28775], 4),\n",
       " ([4658, 3962, 5403, 9331, 2204, 2833], 4),\n",
       " ([2307, 7954, 3976, 6240, 8616, 2036], 5),\n",
       " ([14262, 7903, 2272, 5292, 9397, 2072], 3),\n",
       " ([2005, 2196, 4487, 3736, 9397, 25785], 5),\n",
       " ([2307, 2189, 3114, 3104, 2844, 4392], 5),\n",
       " ([2045, 25933, 2480, 2204, 2051, 2767], 1),\n",
       " ([24970, 23624, 10841, 2099, 3114, 3976], 5),\n",
       " ([2190, 9726, 2052, 2066, 7949, 3819], 4),\n",
       " ([2521, 2204, 2393, 3114, 2173, 6708], 5),\n",
       " ([10825, 2149, 18081, 4190, 20130, 2600], 5),\n",
       " ([24951, 2290, 25933, 2480, 19430, 2102], 5),\n",
       " ([18612, 12183, 18901, 2253, 3807, 2994], 1),\n",
       " ([2173, 27136, 13058, 5313, 2304, 2373], 4),\n",
       " ([4654, 4842, 2072, 24970, 14262, 7903], 3),\n",
       " ([8909, 2360, 10973, 2052, 2126, 2785], 2),\n",
       " ([2342, 9377, 4687, 7615, 2517, 5310], 3),\n",
       " ([3902, 2072, 2128, 2140, 4248, 3669], 4),\n",
       " ([3524, 12530, 2154, 2051, 3328, 1999], 5),\n",
       " ([5470, 6895, 5470, 6895, 11281, 2361], 5),\n",
       " ([8241, 2327, 2165, 2307, 2729, 2149], 5),\n",
       " ([2307, 3199, 3671, 2613, 3669, 4946], 3),\n",
       " ([4121, 12183, 2613, 3669, 3835, 3095], 5),\n",
       " ([4121, 2064, 2025, 2131, 5305, 2009], 1),\n",
       " ([2767, 3669, 2052, 2152, 3669, 16755], 3),\n",
       " ([2058, 18098, 3446, 14262, 7903, 4030], 5),\n",
       " ([11891, 2196, 2272, 2067, 2001, 2102], 2),\n",
       " ([15624, 15624, 2502, 17207, 2480, 3199], 4),\n",
       " ([2482, 2047, 2944, 3631, 3204, 2085], 5),\n",
       " ([3011, 2393, 4067, 3835, 5353, 4477], 1),\n",
       " ([8040, 9072, 5313, 4550, 3198, 3335], 3),\n",
       " ([2190, 2833, 24970, 7276, 5684, 4183], 5),\n",
       " ([2190, 10733, 2919, 2518, 4299, 3553], 3),\n",
       " ([2632, 4576, 24608, 9518, 2147, 2007], 1),\n",
       " ([2684, 2293, 2173, 2172, 2215, 2204], 5),\n",
       " ([2344, 2296, 2705, 21100, 5794, 2094], 5),\n",
       " ([6429, 3669, 2204, 12666, 2063, 3835], 3),\n",
       " ([2307, 2173, 25210, 6904, 8569, 2140], 3),\n",
       " ([8241, 2440, 2072, 2113, 12183, 2569], 3),\n",
       " ([2365, 3328, 2435, 2307, 2606, 12690], 1),\n",
       " ([2330, 4920, 2632, 4576, 2204, 2051], 5),\n",
       " ([2452, 5127, 2205, 2173, 5684, 4183], 5),\n",
       " ([2058, 18098, 2435, 15610, 3835, 2393], 3),\n",
       " ([4687, 2709, 8637, 2151, 3775, 2213], 1),\n",
       " ([2334, 17260, 18416, 2767, 3669, 3626], 5),\n",
       " ([2293, 22894, 9541, 3869, 11937, 3597, 2833], 1),\n",
       " ([2190, 2833, 4797, 17688, 2224, 5372, 3669], 5),\n",
       " ([5843, 12347, 6943, 2307, 2001, 2102, 2051], 1),\n",
       " ([2071, 3198, 2005, 2272, 4521, 2293, 2009], 1),\n",
       " ([2307, 2833, 2204, 3976, 5684, 4183, 2237], 4),\n",
       " ([3013, 3609, 2307, 2131, 2843, 19394, 2147], 1),\n",
       " ([4687, 4654, 4842, 2072, 9518, 2071, 22512], 5),\n",
       " ([6976, 6265, 3962, 14262, 7903, 3671, 2204], 2),\n",
       " ([6723, 2833, 17894, 2714, 2625, 11937, 16643], 5),\n",
       " ([2158, 2173, 2204, 10424, 2072, 7975, 3453], 5),\n",
       " ([2165, 2307, 2729, 7997, 4189, 3976, 4067], 5),\n",
       " ([3942, 4762, 17894, 3095, 3835, 10733, 2204], 4),\n",
       " ([5987, 2833, 2488, 3976, 7954, 24443, 2099], 5),\n",
       " ([2224, 2928, 11011, 2095, 2307, 3828, 4171], 3),\n",
       " ([13012, 2843, 2173, 2190, 2081, 2172, 2488], 3),\n",
       " ([19461, 3630, 1038, 17960, 8197, 2272, 2485], 3),\n",
       " ([2165, 4638, 3902, 2072, 9805, 7382, 2072], 5),\n",
       " ([2253, 2307, 15890, 24970, 3095, 2767, 3669], 5),\n",
       " ([5684, 4183, 2173, 2293, 13877, 2767, 3669], 1),\n",
       " ([11113, 2140, 3328, 2835, 2112, 2072, 3524], 4),\n",
       " ([2190, 2412, 3835, 2393, 5665, 2272, 2067], 5),\n",
       " ([2234, 2767, 3745, 8288, 12122, 11937, 16643], 3),\n",
       " ([2190, 3573, 2181, 4550, 5812, 2307, 17113], 1),\n",
       " ([17612, 2380, 2175, 9726, 2474, 5831, 14352], 5),\n",
       " ([2157, 2632, 4576, 2272, 13675, 10696, 2009], 1),\n",
       " ([8145, 3846, 26348, 2524, 2600, 3499, 2028], 5),\n",
       " ([2204, 7975, 8962, 11345, 2978, 3976, 2100], 5),\n",
       " ([3972, 28775, 3942, 8840, 11266, 3942, 4299], 5),\n",
       " ([10166, 2561, 3279, 2773, 3696, 7743, 2360], 2),\n",
       " ([21480, 4392, 13012, 21480, 2051, 3972, 28775], 5),\n",
       " ([3105, 4248, 3669, 2288, 2307, 2606, 12690], 1),\n",
       " ([2293, 2173, 2330, 2996, 2444, 2944, 6014], 2),\n",
       " ([2613, 3669, 2718, 3962, 12849, 6030, 3593], 2),\n",
       " ([2190, 18651, 7975, 4067, 10026, 2147, 2411], 5),\n",
       " ([3819, 2327, 2296, 2705, 4067, 1057, 2204], 2),\n",
       " ([2215, 18496, 23801, 2072, 2689, 2099, 3825], 3),\n",
       " ([2919, 14262, 7903, 2051, 2182, 2272, 2067], 5),\n",
       " ([2767, 3669, 2190, 2190, 8254, 2278, 2187], 5),\n",
       " ([2204, 2066, 4086, 2665, 2079, 3393, 2818], 4),\n",
       " ([2980, 2066, 2360, 2341, 2980, 3191, 2072], 5),\n",
       " ([3124, 2191, 6359, 10733, 2482, 3335, 21519], 1),\n",
       " ([25933, 2480, 2417, 12731, 18752, 2307, 3976], 2),\n",
       " ([2702, 3490, 6992, 2290, 3828, 3608, 2377], 3),\n",
       " ([3730, 14262, 2615, 2173, 2360, 10676, 2185], 5),\n",
       " ([2946, 21877, 7361, 2140, 2066, 2067, 2153], 5),\n",
       " ([17894, 3976, 4962, 2099, 2146, 3902, 2072], 5),\n",
       " ([3435, 14955, 4183, 4189, 2204, 4012, 23041], 3),\n",
       " ([2307, 27218, 2891, 27921, 24970, 14262, 7903], 2),\n",
       " ([2293, 6073, 22200, 15180, 25426, 15890, 6073], 5),\n",
       " ([2152, 3669, 28667, 8462, 4859, 2173, 3105], 1),\n",
       " ([12721, 2919, 12403, 2213, 11937, 3367, 5785], 4),\n",
       " ([8241, 2767, 3669, 2393, 2036, 4248, 2344], 4),\n",
       " ([2245, 4687, 8828, 3807, 2051, 5959, 2009], 1),\n",
       " ([5684, 2131, 2474, 4779, 10733, 4067, 2101], 2),\n",
       " ([4840, 3972, 28775, 8288, 11642, 2438, 2835], 4),\n",
       " ([2190, 9545, 2940, 2833, 2307, 3954, 4687], 1),\n",
       " ([2253, 6240, 2852, 2072, 3984, 3335, 3829], 3),\n",
       " ([3835, 3347, 2307, 2047, 11660, 3063, 3198], 4),\n",
       " ([18178, 2229, 2072, 2036, 2767, 3669, 3835], 4),\n",
       " ([2190, 2173, 13433, 21823, 2078, 2391, 2345], 5),\n",
       " ([2224, 2589, 9004, 2151, 2239, 3449, 2015], 5),\n",
       " ([4654, 11837, 2015, 4942, 19362, 10514, 6182], 1),\n",
       " ([2051, 2182, 2234, 2767, 3669, 2204, 2569], 5),\n",
       " ([2833, 4392, 26568, 2546, 2175, 3058, 2154], 1),\n",
       " ([2190, 6887, 2080, 3298, 2272, 2293, 2173], 4),\n",
       " ([2307, 2344, 3221, 2664, 3967, 2307, 4440], 2),\n",
       " ([8648, 3446, 10722, 3393, 5254, 2078, 3802], 4),\n",
       " ([4086, 2729, 2173, 19291, 2094, 2019, 5714], 5),\n",
       " ([7276, 27218, 2891, 27921, 3835, 4438, 3347], 2),\n",
       " ([2293, 2173, 10825, 8719, 3233, 2188, 6187], 5),\n",
       " ([2307, 3962, 2288, 16510, 13774, 2051, 2197], 5),\n",
       " ([2190, 2833, 2110, 8241, 3272, 2067, 2574], 5),\n",
       " ([3835, 5154, 2986, 3435, 14262, 7903, 4067], 1),\n",
       " ([23624, 18151, 2278, 2919, 21480, 1054, 2204], 4),\n",
       " ([5156, 4550, 6904, 6895, 2140, 4067, 2017], 3),\n",
       " ([10094, 18515, 2226, 3393, 1996, 8292, 21864], 4),\n",
       " ([2307, 2173, 10288, 29109, 10424, 2072, 23723], 5),\n",
       " ([2391, 2767, 3669, 2709, 2469, 4067, 4067], 1),\n",
       " ([2204, 2833, 2488, 2474, 5292, 23402, 8943], 3),\n",
       " ([2190, 2833, 4299, 10424, 2072, 18178, 2229], 3),\n",
       " ([2152, 3669, 16755, 2173, 4550, 2833, 2204], 3),\n",
       " ([7842, 10383, 2290, 10733, 10250, 8067, 3089], 4),\n",
       " ([2051, 2693, 2171, 10973, 13342, 4366, 2033], 1),\n",
       " ([2307, 14262, 7903, 2562, 2204, 2147, 3124], 4),\n",
       " ([2293, 3460, 3095, 24501, 26029, 2015, 12726], 5),\n",
       " ([5096, 18651, 7975, 10424, 2072, 25025, 7954], 5),\n",
       " ([2442, 2051, 13366, 5498, 2102, 2175, 2067], 5),\n",
       " ([2131, 2707, 2190, 2173, 2833, 8670, 5638], 1),\n",
       " ([2253, 2051, 2175, 2067, 27545, 3300, 3145], 5),\n",
       " ([2190, 7065, 2545, 5292, 9397, 2072, 3178], 2),\n",
       " ([2307, 2833, 2190, 2833, 13012, 2717, 2190], 3),\n",
       " ([3124, 2307, 3105, 21101, 4848, 6090, 2102], 5),\n",
       " ([24970, 2393, 3959, 2272, 2424, 2157, 4377], 5),\n",
       " ([16755, 10424, 2072, 2036, 6116, 2072, 13012], 2),\n",
       " ([2145, 13012, 10236, 2568, 3514, 11132, 3825], 4),\n",
       " ([4654, 11837, 2015, 15180, 25426, 2442, 13012], 5),\n",
       " ([3129, 2345, 2070, 2705, 2371, 2066, 7438], 1),\n",
       " ([2919, 15890, 2051, 3231, 2235, 4664, 2196], 5),\n",
       " ([17935, 3775, 15890, 19394, 2113, 3709, 2290], 5),\n",
       " ([2293, 2173, 11867, 28775, 11350, 3972, 28775], 1),\n",
       " ([2190, 29525, 2000, 2507, 2852, 15547, 2015], 1),\n",
       " ([10166, 2514, 2092, 2044, 4863, 1059, 4048], 5),\n",
       " ([2234, 2154, 2560, 3465, 3669, 9518, 4248], 4),\n",
       " ([2190, 4139, 15960, 11642, 3660, 16150, 2389], 5),\n",
       " ([2173, 2202, 3954, 3305, 15398, 7481, 3124], 4),\n",
       " ([4664, 24951, 2290, 3565, 2307, 2067, 4067], 4),\n",
       " ([2307, 2173, 4550, 2843, 16661, 3835, 3105], 5),\n",
       " ([17079, 2227, 4487, 28745, 22648, 2773, 2833], 5),\n",
       " ([5470, 10230, 2147, 3949, 2130, 2488, 2711], 3),\n",
       " ([3524, 2345, 2187, 2228, 2589, 3807, 2166], 4),\n",
       " ([2197, 2440, 2008, 2196, 4148, 2022, 29278], 4),\n",
       " ([2732, 9587, 14689, 4747, 4904, 22512, 3126], 4),\n",
       " ([2190, 6265, 28305, 2237, 5684, 4183, 2173], 5),\n",
       " ([4012, 26569, 4687, 4654, 4842, 2072, 5323], 3),\n",
       " ([8241, 2767, 3669, 24857, 2204, 2272, 2067], 5),\n",
       " ([2173, 2307, 2154, 2886, 2079, 19140, 16078], 4),\n",
       " ([2307, 7216, 2833, 10825, 2395, 2204, 11831], 4),\n",
       " ([2293, 2272, 2767, 2172, 4569, 4392, 2204], 5),\n",
       " ([2933, 3942, 2173, 2272, 4012, 26569, 3113], 1),\n",
       " ([2253, 2067, 10166, 11234, 2293, 2833, 4248], 3),\n",
       " ([3013, 3942, 2014, 3697, 2606, 13774, 2009], 3),\n",
       " ([2052, 2307, 2173, 4133, 6865, 2785, 2173], 4),\n",
       " ([4003, 22591, 2213, 14894, 24970, 2442, 13012], 5),\n",
       " ([3942, 2237, 2173, 2191, 2514, 2066, 2334], 1),\n",
       " ([5409, 4392, 3589, 5987, 5247, 2341, 2341], 3),\n",
       " ([2833, 2204, 8241, 4030, 2717, 21159, 2757], 1),\n",
       " ([13012, 23723, 10424, 2072, 7975, 2175, 3308], 5),\n",
       " ([8823, 2051, 2154, 7975, 11642, 4299, 4677], 4),\n",
       " ([2360, 2066, 5610, 6240, 11642, 2272, 2182], 4),\n",
       " ([3942, 3095, 13366, 5498, 2102, 2272, 2067], 5),\n",
       " ([2204, 9686, 5051, 6895, 7842, 14194, 2217], 5),\n",
       " ([7661, 14262, 7903, 6869, 4638, 27211, 2092], 5),\n",
       " ([2173, 2307, 14021, 23644, 2425, 2151, 2239], 5),\n",
       " ([4666, 11234, 2173, 2298, 24665, 3686, 3962], 4),\n",
       " ([5988, 13433, 18719, 16558, 3653, 23102, 2140], 5),\n",
       " ([3347, 2342, 2360, 2062, 2175, 3157, 2099], 4),\n",
       " ([2435, 2235, 18178, 2229, 3465, 11576, 8257], 4),\n",
       " ([7632, 6569, 10439, 3669, 3524, 3124, 2655], 4),\n",
       " ([2204, 6265, 28305, 10036, 3976, 7975, 3608], 1),\n",
       " ([7632, 3573, 2655, 2502, 10973, 2502, 25659], 5),\n",
       " ([2412, 2072, 2051, 2272, 3942, 2717, 21159], 4),\n",
       " ([2307, 14262, 7903, 2307, 2833, 2190, 4596], 4),\n",
       " ([11937, 3367, 12183, 2190, 3066, 2204, 2833], 2),\n",
       " ([2613, 3669, 2204, 10514, 6182, 2190, 4897], 3),\n",
       " ([2228, 22566, 2052, 2025, 2594, 2033, 3328], 5),\n",
       " ([5156, 3653, 6916, 2204, 3976, 3020, 2203], 5),\n",
       " ([2253, 6265, 2833, 2307, 14262, 7903, 2172], 5),\n",
       " ([2293, 2009, 4638, 2039, 16307, 2149, 2489], 4),\n",
       " ([2936, 3902, 2072, 2036, 2124, 15736, 15736], 2),\n",
       " ([13012, 2173, 2051, 5968, 18178, 2229, 3280], 1),\n",
       " ([24646, 2078, 13827, 2521, 3309, 2175, 2063], 4),\n",
       " ([7309, 6039, 4392, 2369, 4675, 2204, 4248], 5),\n",
       " ([2293, 2412, 2072, 2051, 2131, 5377, 19394], 1),\n",
       " ([2288, 2306, 9518, 2224, 14262, 7903, 2237], 5),\n",
       " ([21810, 2072, 4679, 2422, 2307, 2569, 2295], 3),\n",
       " ([4687, 2933, 2709, 6904, 4328, 3669, 2574], 4),\n",
       " ([2293, 23624, 5724, 23624, 18151, 2278, 4299], 5),\n",
       " ([3124, 3835, 2393, 7276, 18414, 2594, 5787], 2),\n",
       " ([22035, 2102, 8081, 3825, 6635, 3669, 2165], 4),\n",
       " ([3962, 2006, 2307, 14894, 3819, 4664, 3976], 4),\n",
       " ([3114, 3976, 3972, 28775, 3256, 6949, 2092], 5),\n",
       " ([3565, 9518, 24970, 11748, 2226, 3954, 17070], 5),\n",
       " ([2502, 5723, 3100, 4654, 11837, 2015, 2502], 5),\n",
       " ([2253, 2067, 2117, 4067, 2307, 14262, 7903], 2),\n",
       " ([4654, 11837, 2015, 14262, 7903, 2204, 2067], 5),\n",
       " ([2293, 3942, 2688, 2307, 8145, 2092, 2556], 4),\n",
       " ([3789, 6861, 11345, 2052, 2066, 19116, 23082], 5),\n",
       " ([2600, 2036, 2489, 8369, 7975, 10236, 2088], 5),\n",
       " ([7107, 14976, 4511, 4392, 3809, 2081, 2154], 3),\n",
       " ([2173, 2030, 8376, 16344, 2012, 6528, 2102], 4),\n",
       " ([12824, 2215, 2203, 2202, 2729, 2204, 3066], 1),\n",
       " ([2488, 2204, 2173, 4550, 2711, 3198, 2005], 5),\n",
       " ([17463, 2906, 3524, 5507, 19646, 4276, 3524], 5),\n",
       " ([2307, 2606, 12690, 4248, 1041, 26989, 6895], 5),\n",
       " ([2833, 2204, 2224, 2293, 2173, 2175, 2067], 5),\n",
       " ([2204, 2833, 3435, 14262, 7903, 3114, 3976], 2),\n",
       " ([2293, 3942, 6987, 2632, 4576, 2272, 2868], 5),\n",
       " ([2288, 4392, 21934, 24759, 9436, 2594, 5313], 4),\n",
       " ([15180, 25426, 2240, 3124, 4469, 18157, 2482], 5),\n",
       " ([24665, 5243, 2015, 27304, 2204, 6265, 3976], 2),\n",
       " ([2179, 2694, 2215, 3976, 8369, 7216, 2007], 5),\n",
       " ([24970, 14262, 7903, 2393, 5271, 3198, 3976], 4),\n",
       " ([12726, 2052, 6592, 2298, 2019, 14573, 2173], 5),\n",
       " ([2307, 2293, 2489, 9090, 26509, 7954, 2205], 5),\n",
       " ([5795, 10514, 6182, 2632, 4576, 2204, 3942], 4),\n",
       " ([2307, 14262, 7903, 4687, 2833, 13012, 26509], 1),\n",
       " ...]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_reviews_labels = [(review_lab[0], review_lab[1]) for review_lab in reviews_with_len]\n",
    "sorted_reviews_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(32, 1), dtype=int32, numpy=\n",
       " array([[ 8257],\n",
       "        [ 3435],\n",
       "        [ 2067],\n",
       "        [ 6187],\n",
       "        [ 1058],\n",
       "        [24970],\n",
       "        [ 7929],\n",
       "        [ 2485],\n",
       "        [14123],\n",
       "        [ 2307],\n",
       "        [ 5404],\n",
       "        [ 2237],\n",
       "        [ 2293],\n",
       "        [ 2204],\n",
       "        [ 8288],\n",
       "        [ 2205],\n",
       "        [24970],\n",
       "        [ 2732],\n",
       "        [ 2769],\n",
       "        [ 3199],\n",
       "        [ 3095],\n",
       "        [ 1047],\n",
       "        [ 3819],\n",
       "        [ 3435],\n",
       "        [ 2560],\n",
       "        [ 2173],\n",
       "        [ 2485],\n",
       "        [ 4900],\n",
       "        [24970],\n",
       "        [ 2182],\n",
       "        [ 2514],\n",
       "        [ 2168]])>,\n",
       " <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
       " array([3, 5, 1, 2, 5, 5, 3, 5, 2, 4, 5, 4, 3, 5, 5, 1, 2, 4, 4, 2, 5, 5,\n",
       "        5, 2, 5, 1, 5, 4, 5, 1, 5, 5])>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_dataset = tf.data.Dataset.from_generator(lambda: sorted_reviews_labels, output_types=(tf.int32, tf.int32))\n",
    "BATCH_SIZE = 32\n",
    "batched_dataset = processed_dataset.padded_batch(BATCH_SIZE, padded_shapes=((None, ), ()))\n",
    "next(iter(batched_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOTAL_BATCHES = math.ceil(len(sorted_reviews_labels) / BATCH_SIZE)\n",
    "TEST_BATCHES = TOTAL_BATCHES // 10\n",
    "batched_dataset.shuffle(TOTAL_BATCHES)\n",
    "test_data = batched_dataset.take(TEST_BATCHES)\n",
    "train_data = batched_dataset.skip(TEST_BATCHES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TEXT_MODEL(tf.keras.Model):\n",
    "    \n",
    "    def __init__(self,\n",
    "                 vocabulary_size,\n",
    "                 embedding_dimensions=128,\n",
    "                 cnn_filters=50,\n",
    "                 dnn_units=512,\n",
    "                 model_output_classes=2,\n",
    "                 dropout_rate=0.1,\n",
    "                 training=False,\n",
    "                 name=\"text_model\"):\n",
    "        super(TEXT_MODEL, self).__init__(name=name)\n",
    "        \n",
    "        self.embedding = Embedding(vocabulary_size,\n",
    "                                          embedding_dimensions)\n",
    "        self.cnn_layer1 = Conv1D(filters=cnn_filters,\n",
    "                                        kernel_size=2,\n",
    "                                        padding=\"valid\",\n",
    "                                        activation=\"relu\")\n",
    "        self.cnn_layer2 = Conv1D(filters=cnn_filters,\n",
    "                                        kernel_size=3,\n",
    "                                        padding=\"valid\",\n",
    "                                        activation=\"relu\")\n",
    "        self.cnn_layer3 = Conv1D(filters=cnn_filters,\n",
    "                                        kernel_size=4,\n",
    "                                        padding=\"valid\",\n",
    "                                        activation=\"relu\")\n",
    "        self.pool = GlobalMaxPool1D()\n",
    "        \n",
    "        self.dense_1 = Dense(units=dnn_units, activation=\"relu\")\n",
    "        self.dropout = Dropout(rate=dropout_rate)\n",
    "        if model_output_classes == 2:\n",
    "            self.last_dense = Dense(units=1,\n",
    "                                           activation=\"sigmoid\")\n",
    "        else:\n",
    "            self.last_dense = Dense(units=model_output_classes,\n",
    "                                           activation=\"softmax\")\n",
    "    \n",
    "    def call(self, inputs, training):\n",
    "        l = self.embedding(inputs)\n",
    "        l_1 = self.cnn_layer1(l) \n",
    "        l_1 = self.pool(l_1) \n",
    "        l_2 = self.cnn_layer2(l) \n",
    "        l_2 = self.pool(l_2)\n",
    "        l_3 = self.cnn_layer3(l)\n",
    "        l_3 = self.pool(l_3) \n",
    "        \n",
    "        concatenated = tf.concat([l_1, l_2, l_3], axis=-1) # (batch_size, 3 * cnn_filters)\n",
    "        concatenated = self.dense_1(concatenated)\n",
    "        concatenated = self.dropout(concatenated, training)\n",
    "        model_output = self.last_dense(concatenated)\n",
    "        \n",
    "        return model_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_LENGTH = len(tokenizer.vocab)\n",
    "EMB_DIM = 200\n",
    "CNN_FILTERS = 100\n",
    "DNN_UNITS = 256\n",
    "OUTPUT_CLASSES = 2\n",
    "DROPOUT_RATE = 0.2\n",
    "NB_EPOCHS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_model = TEXT_MODEL(vocabulary_size=VOCAB_LENGTH,\n",
    "                        embedding_dimensions=EMB_DIM,\n",
    "                        cnn_filters=CNN_FILTERS,\n",
    "                        dnn_units=DNN_UNITS,\n",
    "                        model_output_classes=OUTPUT_CLASSES,\n",
    "                        dropout_rate=DROPOUT_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_model.compile(loss=\"mse\", optimizer=\"adam\", metrics=['mae', RootMeanSquaredError('rmse')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "   6138/Unknown - 341s 56ms/step - loss: 9.6158 - mae: 2.7597 - rmse: 3.1009"
     ]
    }
   ],
   "source": [
    "text_model.fit(train_data, epochs=NB_EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a Bert Embedding Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, n_fine_tune_layers=10, **kwargs):\n",
    "        self.n_fine_tune_layers = n_fine_tune_layers\n",
    "        self.pooling = \"mean\"\n",
    "        self.trainable = True\n",
    "        self.output_size = 768\n",
    "        super(BertLayer, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "#         config_file = os.path.join(bert_folder, 'bert_config.json')\n",
    "#         checkpoint_file = os.path.join(bert_folder, 'bert_model.ckpt')\n",
    "#         self.bert = load_trained_model_from_checkpoint(config_file, checkpoint_file, training=True, seq_len=150)\n",
    "        bert_path=\"https://tfhub.dev/google/bert_uncased_L-12_H-768_A-12/1\"\n",
    "        self.bert = hub.Module(\n",
    "            bert_path,\n",
    "            trainable=self.trainable,\n",
    "            name=\"{}_module\".format(self.name)\n",
    "        )\n",
    "        trainable_vars = self.bert.variables\n",
    "    \n",
    "        if self.pooling == \"first\":\n",
    "            trainable_vars = [var for var in trainable_vars if not \"/cls/\" in var.name]\n",
    "            trainable_layers = [\"pooler/dense\"]\n",
    "        \n",
    "        elif self.pooling == \"mean\":\n",
    "            trainable_vars = [var for var in trainable_vars if not \"/cls/\" in var.name and not \"/pooler/\" in var.name]\n",
    "            trainable_layers = []\n",
    "        else:\n",
    "            raise NameError(f\"Undefined pooling type (must be either first or mean, but is {self.pooling}\")\n",
    "\n",
    "        # Select how many layers to fine tune\n",
    "        for i in range(self.n_fine_tune_layers):\n",
    "            trainable_layers.append(f\"encoder/layer_{str(11 - i)}\")\n",
    "\n",
    "        # Update trainable vars to contain only the specified layers\n",
    "        trainable_vars = [var for var in trainable_vars if any([l in var.name for l in trainable_layers])]\n",
    "\n",
    "        # Add to trainable weights\n",
    "        for var in trainable_vars:\n",
    "            self._trainable_weights.append(var)\n",
    "        \n",
    "        # Add non-trainable weights\n",
    "        for var in self.bert.variables:\n",
    "            if var not in self._trainable_weights:\n",
    "                self._non_trainable_weights.append(var)\n",
    "        \n",
    "        super(BertLayer, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        inputs = [K.cast(x, dtype=\"int32\") for x in inputs]\n",
    "        input_ids, input_mask, segment_ids = inputs\n",
    "        bert_inputs = dict(\n",
    "            input_ids=input_ids, input_mask=input_mask, segment_ids=segment_ids\n",
    "        )\n",
    "        if self.pooling == \"first\":\n",
    "            pooled = self.bert(inputs=bert_inputs, signature=\"tokens\", as_dict=True)[\"pooled_output\"]\n",
    "        elif self.pooling == \"mean\":\n",
    "            result = self.bert(inputs=bert_inputs, signature=\"tokens\", as_dict=True)[\"sequence_output\"]\n",
    "\n",
    "            mul_mask = lambda x, m: x * tf.expand_dims(m, axis=-1)\n",
    "            masked_reduce_mean = lambda x, m: tf.reduce_sum(mul_mask(x, m), axis=1) / (\n",
    "                    tf.reduce_sum(m, axis=1, keepdims=True) + 1e-10)\n",
    "            input_mask = tf.cast(input_mask, tf.float32)\n",
    "            pooled = masked_reduce_mean(result, input_mask)\n",
    "        else:\n",
    "            raise NameError(f\"Undefined pooling type (must be either first or mean, but is {self.pooling}\")\n",
    "\n",
    "        return pooled\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], self.output_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "variable_scope bert_layer_2_module/ was unused but the corresponding name_scope was already taken.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-610203ebd402>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     35\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m \u001b[0mm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfit_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcreate_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-13-610203ebd402>\u001b[0m in \u001b[0;36mcreate_model\u001b[1;34m()\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[0mbert_inputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0min_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0min_mask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0min_segment\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m     \u001b[0mbert_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBertLayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_fine_tune_layers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbert_inputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mt:\\python\\python38\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    923\u001b[0m     \u001b[1;31m# >> model = tf.keras.Model(inputs, outputs)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    924\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0m_in_functional_construction_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 925\u001b[1;33m       return self._functional_construction_call(inputs, args, kwargs,\n\u001b[0m\u001b[0;32m    926\u001b[0m                                                 input_list)\n\u001b[0;32m    927\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mt:\\python\\python38\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m_functional_construction_call\u001b[1;34m(self, inputs, args, kwargs, input_list)\u001b[0m\n\u001b[0;32m   1096\u001b[0m         \u001b[1;31m# Build layer if applicable (if the `build` method has been\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1097\u001b[0m         \u001b[1;31m# overridden).\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1098\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_build\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1099\u001b[0m         \u001b[0mcast_inputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cast_inputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1100\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mt:\\python\\python38\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m_maybe_build\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2641\u001b[0m         \u001b[1;31m# operations.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2642\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmaybe_init_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2643\u001b[1;33m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint:disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2644\u001b[0m       \u001b[1;31m# We must set also ensure that the layer is marked as built, and the build\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2645\u001b[0m       \u001b[1;31m# shape is stored since user defined build functions may not be calling\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-12-869121cb351a>\u001b[0m in \u001b[0;36mbuild\u001b[1;34m(self, input_shape)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;31m#         self.bert = load_trained_model_from_checkpoint(config_file, checkpoint_file, training=True, seq_len=150)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0mbert_path\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"https://tfhub.dev/google/bert_uncased_L-12_H-768_A-12/1\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m         self.bert = hub.Module(\n\u001b[0m\u001b[0;32m     15\u001b[0m             \u001b[0mbert_path\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m             \u001b[0mtrainable\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainable\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mt:\\python\\python38\\lib\\site-packages\\tensorflow_hub\\module.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, spec, trainable, name, tags)\u001b[0m\n\u001b[0;32m    165\u001b[0m       \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"No such graph variant: tags=%r\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mtags\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    166\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 167\u001b[1;33m     \u001b[0mabs_state_scope\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_try_get_state_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmark_name_scope_used\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    168\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mabs_state_scope\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"/\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    169\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mt:\\python\\python38\\lib\\site-packages\\tensorflow_hub\\module.py\u001b[0m in \u001b[0;36m_try_get_state_scope\u001b[1;34m(name, mark_name_scope_used)\u001b[0m\n\u001b[0;32m    396\u001b[0m     \u001b[0munique_name_scope\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmark_name_scope_used\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"/\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    397\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0munique_name_scope\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mabs_state_scope\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 398\u001b[1;33m       raise RuntimeError(\n\u001b[0m\u001b[0;32m    399\u001b[0m           \u001b[1;34m\"variable_scope %s was unused but the corresponding \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    400\u001b[0m           \"name_scope was already taken.\" % abs_state_scope)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: variable_scope bert_layer_2_module/ was unused but the corresponding name_scope was already taken."
     ]
    }
   ],
   "source": [
    "def fit_model(model, epochs=3, batch_size=256, loss='mse', optimizer='adam', metrics=['mae', RootMeanSquaredError('rmse')]):\n",
    "    model.compile(loss=loss, optimizer=optimizer, metrics=metrics)\n",
    "    r = model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_data=(X_test, y_test))\n",
    "    plot(r)\n",
    "    return model, r\n",
    "\n",
    "def plot(r):\n",
    "    plt.xlabel('# epochs')\n",
    "    length = len(r.history[next(iter(r.history))])\n",
    "    plt.xticks(np.arange(length), np.arange(1, length+1))\n",
    "    plt.plot(r.history['loss'], label='loss')\n",
    "    plt.plot(r.history['val_loss'], label='val_loss')\n",
    "    plt.plot(r.history['mae'], label='mae')\n",
    "    plt.plot(r.history['val_mae'], 'm', label='val_mae')\n",
    "    plt.plot(r.history['rmse'], label='rmse')\n",
    "    plt.plot(r.history['val_rmse'], 'm', label='val_rmse')\n",
    "    plt.legend()\n",
    "\n",
    "\n",
    "def create_model():\n",
    "    D = 100\n",
    "                    \n",
    "    # Build model\n",
    "    in_id = tf.keras.layers.Input(shape=(150,), name=\"input_ids\")\n",
    "    in_mask = tf.keras.layers.Input(shape=(150,), name=\"input_masks\")\n",
    "    in_segment = tf.keras.layers.Input(shape=(150,), name=\"segment_ids\")\n",
    "    bert_inputs = [in_id, in_mask, in_segment]\n",
    "    \n",
    "    bert_output = BertLayer(n_fine_tune_layers=3)(bert_inputs)\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(bert_output)\n",
    "    model.add(Dense(1))\n",
    "    model.summary(105)\n",
    "    return model\n",
    "\n",
    "m, r = fit_model(create_model(), epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://stackabuse.com/text-classification-with-bert-tokenizer-and-tf-2-0-in-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
